{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1hamzaiqbal/MFCLIP_acv/blob/aidan%2Fgaussianlowpass/mf_clip_initial_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzfIg5NpoHNm",
        "outputId": "d489f13b-92af-41d0-ae9b-08153b774c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov  5 03:31:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   32C    P0             52W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "/content\n",
            "Cloning into 'MFCLIP_acv'...\n",
            "remote: Enumerating objects: 560, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 560 (delta 30), reused 10 (delta 10), pack-reused 519 (from 2)\u001b[K\n",
            "Receiving objects: 100% (560/560), 6.90 MiB | 20.96 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n",
            "/content/MFCLIP_acv\n",
            "Branch 'aidan/gaussianlowpass' set up to track remote branch 'aidan/gaussianlowpass' from 'origin'.\n",
            "Switched to a new branch 'aidan/gaussianlowpass'\n"
          ]
        }
      ],
      "source": [
        "# 0) GPU + repo\n",
        "!nvidia-smi\n",
        "%cd /content\n",
        "!git clone https://github.com/1hamzaiqbal/MFCLIP_acv.git\n",
        "%cd MFCLIP_acv/\n",
        "!git checkout aidan/gaussianlowpass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDljgHXio74B",
        "outputId": "a843b05d-8e8f-4452-eadc-a2cdaf50b7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.21)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ignite\n",
            "  Downloading ignite-1.1.0-py2.py3-none-any.whl.metadata (856 bytes)\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ignite) (2.32.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from ignite) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pytorch-ignite) (25.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from foolbox) (3.1.45)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds) (2.5.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading pytorch_ignite-0.5.3-py3-none-any.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.8/343.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: yacs, ruamel.yaml.clib, littleutils, ftfy, eagerpy, ruamel.yaml, outdated, ignite, foolbox, pytorch-ignite, ogb, wilds\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4 ftfy-6.3.1 ignite-1.1.0 littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 pytorch-ignite-0.5.3 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 wilds-2.0.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# 1) Deps\n",
        "!pip install torch torchvision timm einops yacs tqdm opencv-python scikit-learn scipy pyyaml ruamel.yaml ignite pytorch-ignite foolbox pandas matplotlib seaborn wilds ftfy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These next two codeblocks are only necessary if the data is not already downloaded, @Jun feel free to ignore, just ensure that the commands for training are directed to your datafiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfYAXPuMo_WM",
        "outputId": "3a52e857-9c61-4d03-ce43-91ef2ed5e013"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 792M/792M [00:44<00:00, 17.7MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:02<00:00, 9.21MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oxford Pets downloaded to /content/data\n"
          ]
        }
      ],
      "source": [
        "# 2) Data (example: Oxford Pets into /content/data/oxford_pets)\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "root = Path(\"/content/data/\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "_ = OxfordIIITPet(root=str(root), download=True, transform=transforms.ToTensor())\n",
        "print(\"Oxford Pets downloaded to\", root)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IkuWiy4X1ZG",
        "outputId": "df0ce07b-d530-4a28-c613-c11d6dd6003b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 345M/345M [00:16<00:00, 20.9MB/s]\n",
            "100%|██████████| 502/502 [00:00<00:00, 1.32MB/s]\n",
            "100%|██████████| 15.0k/15.0k [00:00<00:00, 30.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oxford Flowers 102 downloaded to /content/data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import Flowers102\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up data root directory\n",
        "root = Path(\"/content/data/\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download and transform the dataset\n",
        "_ = Flowers102(\n",
        "    root=str(root),\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "print(\"Oxford Flowers 102 downloaded to\", root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L4JipAfqEIB",
        "outputId": "acf5d18a-3425-45f3-84ec-1c286c28645e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-05 05:21:59.583802: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 05:21:59.601413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762320119.622699   37474 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762320119.629136   37474 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762320119.645869   37474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762320119.645911   37474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762320119.645915   37474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762320119.645918   37474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:21:59.650721: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a pink primrose, a type of flower.', 'a photo of a hard-leaved pocket orchid, a type of flower.', 'a photo of a canterbury bells, a type of flower.', 'a photo of a sweet pea, a type of flower.', 'a photo of a english marigold, a type of flower.', 'a photo of a tiger lily, a type of flower.', 'a photo of a moon orchid, a type of flower.', 'a photo of a bird of paradise, a type of flower.', 'a photo of a monkshood, a type of flower.', 'a photo of a globe thistle, a type of flower.', 'a photo of a snapdragon, a type of flower.', \"a photo of a colt's foot, a type of flower.\", 'a photo of a king protea, a type of flower.', 'a photo of a spear thistle, a type of flower.', 'a photo of a yellow iris, a type of flower.', 'a photo of a globe-flower, a type of flower.', 'a photo of a purple coneflower, a type of flower.', 'a photo of a peruvian lily, a type of flower.', 'a photo of a balloon flower, a type of flower.', 'a photo of a giant white arum lily, a type of flower.', 'a photo of a fire lily, a type of flower.', 'a photo of a pincushion flower, a type of flower.', 'a photo of a fritillary, a type of flower.', 'a photo of a red ginger, a type of flower.', 'a photo of a grape hyacinth, a type of flower.', 'a photo of a corn poppy, a type of flower.', 'a photo of a prince of wales feathers, a type of flower.', 'a photo of a stemless gentian, a type of flower.', 'a photo of a artichoke, a type of flower.', 'a photo of a sweet william, a type of flower.', 'a photo of a carnation, a type of flower.', 'a photo of a garden phlox, a type of flower.', 'a photo of a love in the mist, a type of flower.', 'a photo of a mexican aster, a type of flower.', 'a photo of a alpine sea holly, a type of flower.', 'a photo of a ruby-lipped cattleya, a type of flower.', 'a photo of a cape flower, a type of flower.', 'a photo of a great masterwort, a type of flower.', 'a photo of a siam tulip, a type of flower.', 'a photo of a lenten rose, a type of flower.', 'a photo of a barbeton daisy, a type of flower.', 'a photo of a daffodil, a type of flower.', 'a photo of a sword lily, a type of flower.', 'a photo of a poinsettia, a type of flower.', 'a photo of a bolero deep blue, a type of flower.', 'a photo of a wallflower, a type of flower.', 'a photo of a marigold, a type of flower.', 'a photo of a buttercup, a type of flower.', 'a photo of a oxeye daisy, a type of flower.', 'a photo of a common dandelion, a type of flower.', 'a photo of a petunia, a type of flower.', 'a photo of a wild pansy, a type of flower.', 'a photo of a primula, a type of flower.', 'a photo of a sunflower, a type of flower.', 'a photo of a pelargonium, a type of flower.', 'a photo of a bishop of llandaff, a type of flower.', 'a photo of a gaura, a type of flower.', 'a photo of a geranium, a type of flower.', 'a photo of a orange dahlia, a type of flower.', 'a photo of a pink-yellow dahlia, a type of flower.', 'a photo of a cautleya spicata, a type of flower.', 'a photo of a japanese anemone, a type of flower.', 'a photo of a black-eyed susan, a type of flower.', 'a photo of a silverbush, a type of flower.', 'a photo of a californian poppy, a type of flower.', 'a photo of a osteospermum, a type of flower.', 'a photo of a spring crocus, a type of flower.', 'a photo of a bearded iris, a type of flower.', 'a photo of a windflower, a type of flower.', 'a photo of a tree poppy, a type of flower.', 'a photo of a gazania, a type of flower.', 'a photo of a azalea, a type of flower.', 'a photo of a water lily, a type of flower.', 'a photo of a rose, a type of flower.', 'a photo of a thorn apple, a type of flower.', 'a photo of a morning glory, a type of flower.', 'a photo of a passion flower, a type of flower.', 'a photo of a lotus, a type of flower.', 'a photo of a toad lily, a type of flower.', 'a photo of a anthurium, a type of flower.', 'a photo of a frangipani, a type of flower.', 'a photo of a clematis, a type of flower.', 'a photo of a hibiscus, a type of flower.', 'a photo of a columbine, a type of flower.', 'a photo of a desert-rose, a type of flower.', 'a photo of a tree mallow, a type of flower.', 'a photo of a magnolia, a type of flower.', 'a photo of a cyclamen, a type of flower.', 'a photo of a watercress, a type of flower.', 'a photo of a canna lily, a type of flower.', 'a photo of a hippeastrum, a type of flower.', 'a photo of a bee balm, a type of flower.', 'a photo of a ball moss, a type of flower.', 'a photo of a foxglove, a type of flower.', 'a photo of a bougainvillea, a type of flower.', 'a photo of a camellia, a type of flower.', 'a photo of a mallow, a type of flower.', 'a photo of a mexican petunia, a type of flower.', 'a photo of a bromelia, a type of flower.', 'a photo of a blanket flower, a type of flower.', 'a photo of a trumpet creeper, a type of flower.', 'a photo of a blackberry lily, a type of flower.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "Epoch: 0, train acc: 0.0600, loss: 4.504824\n",
            "Epoch: 1, train acc: 0.1268, loss: 3.728598\n",
            "Epoch: 2, train acc: 0.1782, loss: 3.381736\n",
            "Epoch: 3, train acc: 0.2014, loss: 3.183812\n",
            "Epoch: 4, train acc: 0.2349, loss: 3.010613\n",
            "Epoch: 5, train acc: 0.2641, loss: 2.885777\n",
            "Epoch: 6, train acc: 0.2878, loss: 2.759437\n",
            "Epoch: 7, train acc: 0.2812, loss: 2.736134\n",
            "Epoch: 8, train acc: 0.3158, loss: 2.617347\n",
            "Epoch: 9, train acc: 0.3463, loss: 2.473026\n",
            "Epoch: 10, train acc: 0.3621, loss: 2.412076\n",
            "Epoch: 11, train acc: 0.3810, loss: 2.341689\n",
            "Epoch: 12, train acc: 0.3934, loss: 2.268906\n",
            "Epoch: 13, train acc: 0.4047, loss: 2.214300\n",
            "Epoch: 14, train acc: 0.4282, loss: 2.142554\n",
            "Epoch: 15, train acc: 0.4340, loss: 2.080886\n",
            "Epoch: 16, train acc: 0.4456, loss: 2.020344\n",
            "Epoch: 17, train acc: 0.4743, loss: 1.942278\n",
            "Epoch: 18, train acc: 0.4869, loss: 1.907633\n",
            "Epoch: 19, train acc: 0.4990, loss: 1.813195\n",
            "Epoch: 20, train acc: 0.5161, loss: 1.735920\n",
            "Epoch: 21, train acc: 0.5249, loss: 1.701938\n",
            "Epoch: 22, train acc: 0.5469, loss: 1.627214\n",
            "Epoch: 23, train acc: 0.5426, loss: 1.638321\n",
            "Epoch: 24, train acc: 0.5625, loss: 1.584682\n",
            "Epoch: 25, train acc: 0.5804, loss: 1.486081\n",
            "Epoch: 26, train acc: 0.5925, loss: 1.440758\n",
            "Epoch: 27, train acc: 0.6177, loss: 1.353400\n",
            "Epoch: 28, train acc: 0.6124, loss: 1.371304\n",
            "Epoch: 29, train acc: 0.6258, loss: 1.332133\n",
            "Epoch: 30, train acc: 0.6351, loss: 1.273387\n",
            "Epoch: 31, train acc: 0.6520, loss: 1.223430\n",
            "Epoch: 32, train acc: 0.6545, loss: 1.202713\n",
            "Epoch: 33, train acc: 0.6550, loss: 1.197138\n",
            "Epoch: 34, train acc: 0.6736, loss: 1.161050\n",
            "Epoch: 35, train acc: 0.6920, loss: 1.113165\n",
            "Epoch: 36, train acc: 0.6961, loss: 1.060840\n",
            "Epoch: 37, train acc: 0.6898, loss: 1.075621\n",
            "Epoch: 38, train acc: 0.6920, loss: 1.087833\n",
            "Epoch: 39, train acc: 0.7112, loss: 1.009312\n",
            "Epoch: 40, train acc: 0.7130, loss: 0.997282\n",
            "Epoch: 41, train acc: 0.7208, loss: 0.972147\n",
            "Epoch: 42, train acc: 0.7500, loss: 0.901093\n",
            "Epoch: 43, train acc: 0.7404, loss: 0.899398\n",
            "Epoch: 44, train acc: 0.7442, loss: 0.888279\n",
            "Epoch: 45, train acc: 0.7543, loss: 0.859510\n",
            "Epoch: 46, train acc: 0.7520, loss: 0.851814\n",
            "Epoch: 47, train acc: 0.7812, loss: 0.780158\n",
            "Epoch: 48, train acc: 0.7749, loss: 0.784924\n",
            "Epoch: 49, train acc: 0.7873, loss: 0.735982\n",
            "Epoch: 50, train acc: 0.7966, loss: 0.722890\n",
            "Epoch: 51, train acc: 0.8039, loss: 0.698766\n",
            "Epoch: 52, train acc: 0.8047, loss: 0.679331\n",
            "Epoch: 53, train acc: 0.8087, loss: 0.658860\n",
            "Epoch: 54, train acc: 0.8364, loss: 0.591945\n",
            "Epoch: 55, train acc: 0.8188, loss: 0.647831\n",
            "Epoch: 56, train acc: 0.8211, loss: 0.626858\n",
            "Epoch: 57, train acc: 0.8357, loss: 0.592401\n",
            "Epoch: 58, train acc: 0.8475, loss: 0.551374\n",
            "Epoch: 59, train acc: 0.8349, loss: 0.574887\n",
            "Epoch: 60, train acc: 0.8397, loss: 0.554090\n",
            "Epoch: 61, train acc: 0.8465, loss: 0.552624\n",
            "Epoch: 62, train acc: 0.8619, loss: 0.504321\n",
            "Epoch: 63, train acc: 0.8556, loss: 0.517075\n",
            "Epoch: 64, train acc: 0.8659, loss: 0.507590\n",
            "Epoch: 65, train acc: 0.8677, loss: 0.480955\n",
            "Epoch: 66, train acc: 0.8783, loss: 0.442121\n",
            "Epoch: 67, train acc: 0.8765, loss: 0.448036\n",
            "Epoch: 68, train acc: 0.8831, loss: 0.431146\n",
            "Epoch: 69, train acc: 0.8977, loss: 0.391325\n",
            "Epoch: 70, train acc: 0.8904, loss: 0.393389\n",
            "Epoch: 71, train acc: 0.8879, loss: 0.416558\n",
            "Epoch: 72, train acc: 0.8831, loss: 0.421867\n",
            "Epoch: 73, train acc: 0.8876, loss: 0.418095\n",
            "Epoch: 74, train acc: 0.8957, loss: 0.374459\n",
            "Epoch: 75, train acc: 0.9103, loss: 0.347495\n",
            "Epoch: 76, train acc: 0.9070, loss: 0.345879\n",
            "Epoch: 77, train acc: 0.9027, loss: 0.351156\n",
            "Epoch: 78, train acc: 0.9098, loss: 0.338176\n",
            "Epoch: 79, train acc: 0.9068, loss: 0.349579\n",
            "Epoch: 80, train acc: 0.9133, loss: 0.331177\n",
            "Epoch: 81, train acc: 0.9156, loss: 0.324490\n",
            "Epoch: 82, train acc: 0.9239, loss: 0.293326\n",
            "Epoch: 83, train acc: 0.9156, loss: 0.316625\n",
            "Epoch: 84, train acc: 0.9173, loss: 0.319952\n",
            "Epoch: 85, train acc: 0.9128, loss: 0.318581\n",
            "Epoch: 86, train acc: 0.9297, loss: 0.273461\n",
            "Epoch: 87, train acc: 0.9297, loss: 0.282664\n",
            "Epoch: 88, train acc: 0.9342, loss: 0.262016\n",
            "Epoch: 89, train acc: 0.9365, loss: 0.249157\n",
            "Epoch: 90, train acc: 0.9357, loss: 0.265125\n",
            "Epoch: 91, train acc: 0.9360, loss: 0.257759\n",
            "Epoch: 92, train acc: 0.9388, loss: 0.245613\n",
            "Epoch: 93, train acc: 0.9425, loss: 0.224000\n",
            "Epoch: 94, train acc: 0.9410, loss: 0.225088\n",
            "Epoch: 95, train acc: 0.9403, loss: 0.236583\n",
            "Epoch: 96, train acc: 0.9395, loss: 0.240144\n",
            "Epoch: 97, train acc: 0.9453, loss: 0.220275\n",
            "Epoch: 98, train acc: 0.9491, loss: 0.204044\n",
            "Epoch: 99, train acc: 0.9471, loss: 0.210999\n",
            "Epoch: 100, train acc: 0.9438, loss: 0.218599\n",
            "Epoch: 101, train acc: 0.9519, loss: 0.201991\n",
            "Epoch: 102, train acc: 0.9476, loss: 0.207241\n",
            "Epoch: 103, train acc: 0.9498, loss: 0.191145\n",
            "Epoch: 104, train acc: 0.9549, loss: 0.186567\n",
            "Epoch: 105, train acc: 0.9569, loss: 0.166265\n",
            "Epoch: 106, train acc: 0.9539, loss: 0.183240\n",
            "Epoch: 107, train acc: 0.9602, loss: 0.160846\n",
            "Epoch: 108, train acc: 0.9531, loss: 0.175598\n",
            "Epoch: 109, train acc: 0.9574, loss: 0.164714\n",
            "Epoch: 110, train acc: 0.9630, loss: 0.167934\n",
            "Epoch: 111, train acc: 0.9624, loss: 0.151513\n",
            "Epoch: 112, train acc: 0.9622, loss: 0.156808\n",
            "Epoch: 113, train acc: 0.9647, loss: 0.140397\n",
            "Epoch: 114, train acc: 0.9624, loss: 0.153096\n",
            "Epoch: 115, train acc: 0.9617, loss: 0.163209\n",
            "Epoch: 116, train acc: 0.9672, loss: 0.139992\n",
            "Epoch: 117, train acc: 0.9710, loss: 0.123291\n",
            "Epoch: 118, train acc: 0.9700, loss: 0.126663\n",
            "Epoch: 119, train acc: 0.9745, loss: 0.113856\n",
            "Epoch: 120, train acc: 0.9693, loss: 0.129711\n",
            "Epoch: 121, train acc: 0.9698, loss: 0.129372\n",
            "Epoch: 122, train acc: 0.9682, loss: 0.127033\n",
            "Epoch: 123, train acc: 0.9677, loss: 0.138312\n",
            "Epoch: 124, train acc: 0.9720, loss: 0.128643\n",
            "Epoch: 125, train acc: 0.9708, loss: 0.124195\n",
            "Epoch: 126, train acc: 0.9662, loss: 0.127136\n",
            "Epoch: 127, train acc: 0.9710, loss: 0.124118\n",
            "Epoch: 128, train acc: 0.9693, loss: 0.117726\n",
            "Epoch: 129, train acc: 0.9728, loss: 0.116651\n",
            "Epoch: 130, train acc: 0.9740, loss: 0.114486\n",
            "Epoch: 131, train acc: 0.9723, loss: 0.118810\n",
            "Epoch: 132, train acc: 0.9748, loss: 0.118741\n",
            "Epoch: 133, train acc: 0.9751, loss: 0.104273\n",
            "Epoch: 134, train acc: 0.9776, loss: 0.105941\n",
            "Epoch: 135, train acc: 0.9725, loss: 0.117834\n",
            "Epoch: 136, train acc: 0.9703, loss: 0.124993\n",
            "Epoch: 137, train acc: 0.9725, loss: 0.117001\n",
            "Epoch: 138, train acc: 0.9766, loss: 0.107437\n",
            "Epoch: 139, train acc: 0.9773, loss: 0.104483\n",
            "Epoch: 140, train acc: 0.9756, loss: 0.109109\n",
            "Epoch: 141, train acc: 0.9771, loss: 0.093586\n",
            "Epoch: 142, train acc: 0.9791, loss: 0.096100\n",
            "Epoch: 143, train acc: 0.9793, loss: 0.099555\n",
            "Epoch: 144, train acc: 0.9745, loss: 0.111613\n",
            "Epoch: 145, train acc: 0.9763, loss: 0.111353\n",
            "Epoch: 146, train acc: 0.9700, loss: 0.115288\n",
            "Epoch: 147, train acc: 0.9796, loss: 0.090448\n",
            "Epoch: 148, train acc: 0.9756, loss: 0.109381\n",
            "Epoch: 149, train acc: 0.9758, loss: 0.102268\n",
            "Epoch: 150, train acc: 0.8173, loss: 0.648317\n",
            "Epoch: 151, train acc: 0.6724, loss: 1.193608\n",
            "Epoch: 152, train acc: 0.7329, loss: 0.932457\n",
            "Epoch: 153, train acc: 0.7828, loss: 0.759333\n",
            "Epoch: 154, train acc: 0.8012, loss: 0.697677\n",
            "Epoch: 155, train acc: 0.8032, loss: 0.692020\n",
            "Epoch: 156, train acc: 0.8160, loss: 0.659868\n",
            "Epoch: 157, train acc: 0.8213, loss: 0.618809\n",
            "Epoch: 158, train acc: 0.8501, loss: 0.553643\n",
            "Epoch: 159, train acc: 0.8440, loss: 0.552324\n",
            "Epoch: 160, train acc: 0.8470, loss: 0.555138\n",
            "Epoch: 161, train acc: 0.8513, loss: 0.524501\n",
            "Epoch: 162, train acc: 0.8533, loss: 0.533581\n",
            "Epoch: 163, train acc: 0.8470, loss: 0.554715\n",
            "Epoch: 164, train acc: 0.8586, loss: 0.508926\n",
            "Epoch: 165, train acc: 0.8558, loss: 0.516228\n",
            "Epoch: 166, train acc: 0.8735, loss: 0.453688\n",
            "Epoch: 167, train acc: 0.8700, loss: 0.476698\n",
            "Epoch: 168, train acc: 0.8727, loss: 0.446061\n",
            "Epoch: 169, train acc: 0.8768, loss: 0.450264\n",
            "Epoch: 170, train acc: 0.8692, loss: 0.465820\n",
            "Epoch: 171, train acc: 0.8659, loss: 0.478506\n",
            "Epoch: 172, train acc: 0.8886, loss: 0.424039\n",
            "Epoch: 173, train acc: 0.8909, loss: 0.394780\n",
            "Epoch: 174, train acc: 0.8863, loss: 0.393839\n",
            "Epoch: 175, train acc: 0.8929, loss: 0.394788\n",
            "Epoch: 176, train acc: 0.8884, loss: 0.418233\n",
            "Epoch: 177, train acc: 0.8755, loss: 0.441857\n",
            "Epoch: 178, train acc: 0.8984, loss: 0.375639\n",
            "Epoch: 179, train acc: 0.8896, loss: 0.403040\n",
            "Epoch: 180, train acc: 0.8780, loss: 0.452340\n",
            "Epoch: 181, train acc: 0.8972, loss: 0.389811\n",
            "Epoch: 182, train acc: 0.9131, loss: 0.338208\n",
            "Epoch: 183, train acc: 0.9120, loss: 0.332717\n",
            "Epoch: 184, train acc: 0.9057, loss: 0.350502\n",
            "Epoch: 185, train acc: 0.9105, loss: 0.339621\n",
            "Epoch: 186, train acc: 0.9141, loss: 0.318649\n",
            "Epoch: 187, train acc: 0.9065, loss: 0.355687\n",
            "Epoch: 188, train acc: 0.9090, loss: 0.338232\n",
            "Epoch: 189, train acc: 0.9075, loss: 0.351245\n",
            "Epoch: 190, train acc: 0.9153, loss: 0.313490\n",
            "Epoch: 191, train acc: 0.9100, loss: 0.312897\n",
            "Epoch: 192, train acc: 0.9118, loss: 0.338416\n",
            "Epoch: 193, train acc: 0.9118, loss: 0.330824\n",
            "Epoch: 194, train acc: 0.9252, loss: 0.285375\n",
            "Epoch: 195, train acc: 0.9090, loss: 0.328879\n",
            "Epoch: 196, train acc: 0.9236, loss: 0.291985\n",
            "Epoch: 197, train acc: 0.9204, loss: 0.299655\n",
            "Epoch: 198, train acc: 0.9249, loss: 0.291578\n",
            "Epoch: 199, train acc: 0.9259, loss: 0.283391\n",
            "Epoch: 200, train acc: 0.9307, loss: 0.262422\n",
            "Epoch: 201, train acc: 0.9400, loss: 0.242018\n",
            "Epoch: 202, train acc: 0.9372, loss: 0.258623\n",
            "Epoch: 203, train acc: 0.9264, loss: 0.269126\n",
            "Epoch: 204, train acc: 0.9216, loss: 0.293361\n",
            "Epoch: 205, train acc: 0.9320, loss: 0.260770\n",
            "Epoch: 206, train acc: 0.9403, loss: 0.245645\n",
            "Epoch: 207, train acc: 0.9433, loss: 0.223283\n",
            "Epoch: 208, train acc: 0.9317, loss: 0.260199\n",
            "Epoch: 209, train acc: 0.9428, loss: 0.227135\n",
            "Epoch: 210, train acc: 0.9317, loss: 0.256977\n",
            "Epoch: 211, train acc: 0.9398, loss: 0.239449\n",
            "Epoch: 212, train acc: 0.9355, loss: 0.255894\n",
            "Epoch: 213, train acc: 0.9448, loss: 0.218951\n",
            "Epoch: 214, train acc: 0.9393, loss: 0.234959\n",
            "Epoch: 215, train acc: 0.9443, loss: 0.217072\n",
            "Epoch: 216, train acc: 0.9438, loss: 0.220755\n",
            "Epoch: 217, train acc: 0.9471, loss: 0.209125\n",
            "Epoch: 218, train acc: 0.9461, loss: 0.207274\n",
            "Epoch: 219, train acc: 0.9443, loss: 0.221478\n",
            "Epoch: 220, train acc: 0.9501, loss: 0.201081\n",
            "Epoch: 221, train acc: 0.9463, loss: 0.207731\n",
            "Epoch: 222, train acc: 0.9488, loss: 0.204247\n",
            "Epoch: 223, train acc: 0.9536, loss: 0.207646\n",
            "Epoch: 224, train acc: 0.9546, loss: 0.182777\n",
            "Epoch: 225, train acc: 0.9536, loss: 0.194262\n",
            "Epoch: 226, train acc: 0.9597, loss: 0.175583\n",
            "Epoch: 227, train acc: 0.9501, loss: 0.188152\n",
            "Epoch: 228, train acc: 0.9534, loss: 0.176249\n",
            "Epoch: 229, train acc: 0.9509, loss: 0.196291\n",
            "Epoch: 230, train acc: 0.9551, loss: 0.178364\n",
            "Epoch: 231, train acc: 0.9592, loss: 0.158957\n",
            "Epoch: 232, train acc: 0.9599, loss: 0.162795\n",
            "Epoch: 233, train acc: 0.9599, loss: 0.148397\n",
            "Epoch: 234, train acc: 0.9635, loss: 0.144925\n",
            "Epoch: 235, train acc: 0.9650, loss: 0.144037\n",
            "Epoch: 236, train acc: 0.9665, loss: 0.144183\n",
            "Epoch: 237, train acc: 0.9652, loss: 0.134418\n",
            "Epoch: 238, train acc: 0.9672, loss: 0.131783\n",
            "Epoch: 239, train acc: 0.9637, loss: 0.144269\n",
            "Epoch: 240, train acc: 0.9647, loss: 0.151348\n",
            "Epoch: 241, train acc: 0.9640, loss: 0.144297\n",
            "Epoch: 242, train acc: 0.9718, loss: 0.114254\n",
            "Epoch: 243, train acc: 0.9723, loss: 0.106350\n",
            "Epoch: 244, train acc: 0.9725, loss: 0.118294\n",
            "Epoch: 245, train acc: 0.9705, loss: 0.124896\n",
            "Epoch: 246, train acc: 0.9715, loss: 0.125087\n",
            "Epoch: 247, train acc: 0.9745, loss: 0.113220\n",
            "Epoch: 248, train acc: 0.9740, loss: 0.106289\n",
            "Epoch: 249, train acc: 0.9768, loss: 0.099363\n",
            "Epoch: 250, train acc: 0.9803, loss: 0.090539\n",
            "Epoch: 251, train acc: 0.9748, loss: 0.108356\n",
            "Epoch: 252, train acc: 0.9773, loss: 0.094982\n",
            "Epoch: 253, train acc: 0.9796, loss: 0.089634\n",
            "Epoch: 254, train acc: 0.9725, loss: 0.104980\n",
            "Epoch: 255, train acc: 0.9781, loss: 0.095030\n",
            "Epoch: 256, train acc: 0.9796, loss: 0.091492\n",
            "Epoch: 257, train acc: 0.9814, loss: 0.084085\n",
            "Epoch: 258, train acc: 0.9803, loss: 0.088773\n",
            "Epoch: 259, train acc: 0.9791, loss: 0.082693\n",
            "Epoch: 260, train acc: 0.9758, loss: 0.095515\n",
            "Epoch: 261, train acc: 0.9824, loss: 0.081790\n",
            "Epoch: 262, train acc: 0.9816, loss: 0.077773\n",
            "Epoch: 263, train acc: 0.9839, loss: 0.068891\n",
            "Epoch: 264, train acc: 0.9798, loss: 0.078279\n",
            "Epoch: 265, train acc: 0.9814, loss: 0.079633\n",
            "Epoch: 266, train acc: 0.9824, loss: 0.076761\n",
            "Epoch: 267, train acc: 0.9851, loss: 0.074852\n",
            "Epoch: 268, train acc: 0.9854, loss: 0.067960\n",
            "Epoch: 269, train acc: 0.9808, loss: 0.079355\n",
            "Epoch: 270, train acc: 0.9859, loss: 0.068502\n",
            "Epoch: 271, train acc: 0.9816, loss: 0.073343\n",
            "Epoch: 272, train acc: 0.9829, loss: 0.078815\n",
            "Epoch: 273, train acc: 0.9841, loss: 0.066508\n",
            "Epoch: 274, train acc: 0.9854, loss: 0.070246\n",
            "Epoch: 275, train acc: 0.9854, loss: 0.060779\n",
            "Epoch: 276, train acc: 0.9859, loss: 0.060356\n",
            "Epoch: 277, train acc: 0.9846, loss: 0.062214\n",
            "Epoch: 278, train acc: 0.9831, loss: 0.067668\n",
            "Epoch: 279, train acc: 0.9856, loss: 0.061881\n",
            "Epoch: 280, train acc: 0.9844, loss: 0.059405\n",
            "Epoch: 281, train acc: 0.9846, loss: 0.062557\n",
            "Epoch: 282, train acc: 0.9859, loss: 0.061046\n",
            "Epoch: 283, train acc: 0.9854, loss: 0.060514\n",
            "Epoch: 284, train acc: 0.9899, loss: 0.052026\n",
            "Epoch: 285, train acc: 0.9899, loss: 0.053136\n",
            "Epoch: 286, train acc: 0.9892, loss: 0.052748\n",
            "Epoch: 287, train acc: 0.9877, loss: 0.051045\n",
            "Epoch: 288, train acc: 0.9894, loss: 0.051366\n",
            "Epoch: 289, train acc: 0.9897, loss: 0.047646\n",
            "Epoch: 290, train acc: 0.9882, loss: 0.055411\n",
            "Epoch: 291, train acc: 0.9874, loss: 0.056372\n",
            "Epoch: 292, train acc: 0.9879, loss: 0.055024\n",
            "Epoch: 293, train acc: 0.9877, loss: 0.056291\n",
            "Epoch: 294, train acc: 0.9884, loss: 0.053765\n",
            "Epoch: 295, train acc: 0.9874, loss: 0.059183\n",
            "Epoch: 296, train acc: 0.9854, loss: 0.061892\n",
            "Epoch: 297, train acc: 0.9902, loss: 0.050824\n",
            "Epoch: 298, train acc: 0.9919, loss: 0.044615\n",
            "Epoch: 299, train acc: 0.9869, loss: 0.058721\n",
            "eval acc: 0.8384\n",
            "saved target model\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train the target models, only necessary if they are not already trained. Replace rn18 with whatever model you want to train.\n",
        "\"\"\"\n",
        "!python main.py --dataset oxford_flowers --root /content/data --dataset-config-file configs/datasets/oxford_flowers.yaml --config-file configs/trainers/CoOp/rn50.yaml --flag train_scratch \\\n",
        "        --num_epoch 300 \\\n",
        "        --target \"rn18\" \\\n",
        "        --lr 0.1 \\\n",
        "        --bs 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_3qWsaMC7qL",
        "outputId": "2907dabb-5463-4af6-e79c-bfffcce47837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-05 04:04:06.097579: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 04:04:06.115881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762315446.137442   10292 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762315446.144006   10292 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762315446.160882   10292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762315446.160920   10292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762315446.160923   10292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762315446.160926   10292 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 04:04:06.165890: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "head param:\n",
            "{'feat_dim': 1024, 'num_class': 37, 'margin_arc': 0.15, 'margin_am': 0.0, 'scale': 16}\n",
            "Epoch: 0, train acc: 0.1291, loss: 0.285176\n",
            "Epoch: 1, train acc: 0.0589, loss: 0.187535\n",
            "Epoch: 2, train acc: 0.0499, loss: 0.167588\n",
            "Epoch: 3, train acc: 0.0502, loss: 0.155673\n",
            "Epoch: 4, train acc: 0.0452, loss: 0.149228\n",
            "Epoch: 5, train acc: 0.0455, loss: 0.140685\n",
            "Epoch: 6, train acc: 0.0428, loss: 0.135199\n",
            "Epoch: 7, train acc: 0.0400, loss: 0.129059\n",
            "Epoch: 8, train acc: 0.0425, loss: 0.128607\n",
            "Epoch: 9, train acc: 0.0450, loss: 0.127597\n",
            "Epoch: 10, train acc: 0.0362, loss: 0.122393\n",
            "Epoch: 11, train acc: 0.0403, loss: 0.115227\n",
            "Epoch: 12, train acc: 0.0345, loss: 0.107376\n",
            "Epoch: 13, train acc: 0.0370, loss: 0.105579\n",
            "Epoch: 14, train acc: 0.0343, loss: 0.101977\n",
            "Epoch: 15, train acc: 0.0381, loss: 0.095428\n",
            "Epoch: 16, train acc: 0.0326, loss: 0.098770\n",
            "Epoch: 17, train acc: 0.0362, loss: 0.088251\n",
            "Epoch: 18, train acc: 0.0312, loss: 0.084558\n",
            "Epoch: 19, train acc: 0.0302, loss: 0.084365\n",
            "Epoch: 20, train acc: 0.0310, loss: 0.082365\n",
            "Epoch: 21, train acc: 0.0312, loss: 0.076981\n",
            "Epoch: 22, train acc: 0.0291, loss: 0.067213\n",
            "Epoch: 23, train acc: 0.0280, loss: 0.074858\n",
            "Epoch: 24, train acc: 0.0260, loss: 0.066338\n",
            "Epoch: 25, train acc: 0.0271, loss: 0.061324\n",
            "Epoch: 26, train acc: 0.0241, loss: 0.057123\n",
            "Epoch: 27, train acc: 0.0192, loss: 0.054340\n",
            "Epoch: 28, train acc: 0.0247, loss: 0.050540\n",
            "Epoch: 29, train acc: 0.0219, loss: 0.051667\n",
            "Epoch: 30, train acc: 0.0222, loss: 0.045243\n",
            "Epoch: 31, train acc: 0.0222, loss: 0.046158\n",
            "Epoch: 32, train acc: 0.0206, loss: 0.041181\n",
            "Epoch: 33, train acc: 0.0219, loss: 0.041297\n",
            "Epoch: 34, train acc: 0.0192, loss: 0.036022\n",
            "Epoch: 35, train acc: 0.0186, loss: 0.032977\n",
            "Epoch: 36, train acc: 0.0219, loss: 0.036453\n",
            "Epoch: 37, train acc: 0.0173, loss: 0.030213\n",
            "Epoch: 38, train acc: 0.0217, loss: 0.034071\n",
            "Epoch: 39, train acc: 0.0173, loss: 0.031652\n",
            "Epoch: 40, train acc: 0.0167, loss: 0.027972\n",
            "Epoch: 41, train acc: 0.0186, loss: 0.026038\n",
            "Epoch: 42, train acc: 0.0192, loss: 0.033824\n",
            "Epoch: 43, train acc: 0.0225, loss: 0.027338\n",
            "Epoch: 44, train acc: 0.0186, loss: 0.025109\n",
            "Epoch: 45, train acc: 0.0271, loss: 0.057640\n",
            "Epoch: 46, train acc: 0.0244, loss: 0.059786\n",
            "Epoch: 47, train acc: 0.0269, loss: 0.057378\n",
            "Epoch: 48, train acc: 0.0208, loss: 0.057332\n",
            "Epoch: 49, train acc: 0.0244, loss: 0.056452\n",
            "Epoch: 50, train acc: 0.0247, loss: 0.055683\n",
            "Epoch: 51, train acc: 0.0200, loss: 0.053155\n",
            "Epoch: 52, train acc: 0.0208, loss: 0.050018\n",
            "Epoch: 53, train acc: 0.0189, loss: 0.046044\n",
            "Epoch: 54, train acc: 0.0211, loss: 0.040777\n",
            "Epoch: 55, train acc: 0.0189, loss: 0.039277\n",
            "Epoch: 56, train acc: 0.0197, loss: 0.038655\n",
            "Epoch: 57, train acc: 0.0197, loss: 0.036911\n",
            "Epoch: 58, train acc: 0.0195, loss: 0.039581\n",
            "Epoch: 59, train acc: 0.0211, loss: 0.032384\n",
            "Epoch: 60, train acc: 0.0184, loss: 0.033660\n",
            "Epoch: 61, train acc: 0.0208, loss: 0.032795\n",
            "Epoch: 62, train acc: 0.0170, loss: 0.026619\n",
            "Epoch: 63, train acc: 0.0151, loss: 0.021460\n",
            "Epoch: 64, train acc: 0.0134, loss: 0.020716\n",
            "Epoch: 65, train acc: 0.0148, loss: 0.015265\n",
            "Epoch: 66, train acc: 0.0175, loss: 0.016295\n",
            "Epoch: 67, train acc: 0.0162, loss: 0.010694\n",
            "Epoch: 68, train acc: 0.0184, loss: 0.012585\n",
            "Epoch: 69, train acc: 0.0162, loss: 0.008552\n",
            "Epoch: 70, train acc: 0.0137, loss: 0.007726\n",
            "Epoch: 71, train acc: 0.0140, loss: -0.000500\n",
            "Epoch: 72, train acc: 0.0132, loss: 0.000341\n",
            "Epoch: 73, train acc: 0.0107, loss: -0.002931\n",
            "Epoch: 74, train acc: 0.0112, loss: -0.005600\n",
            "Epoch: 75, train acc: 0.0099, loss: -0.008736\n",
            "Epoch: 76, train acc: 0.0121, loss: -0.007015\n",
            "Epoch: 77, train acc: 0.0101, loss: -0.015342\n",
            "Epoch: 78, train acc: 0.0137, loss: -0.015421\n",
            "Epoch: 79, train acc: 0.0112, loss: -0.014215\n",
            "Epoch: 80, train acc: 0.0093, loss: -0.014557\n",
            "Epoch: 81, train acc: 0.0090, loss: -0.017150\n",
            "Epoch: 82, train acc: 0.0104, loss: -0.017285\n",
            "Epoch: 83, train acc: 0.0090, loss: -0.022818\n",
            "Epoch: 84, train acc: 0.0118, loss: -0.016362\n",
            "Epoch: 85, train acc: 0.0088, loss: -0.019317\n",
            "Epoch: 86, train acc: 0.0104, loss: -0.022538\n",
            "Epoch: 87, train acc: 0.0077, loss: -0.020964\n",
            "Epoch: 88, train acc: 0.0107, loss: -0.023506\n",
            "Epoch: 89, train acc: 0.0077, loss: -0.024327\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "command to train unet\n",
        "\"\"\"\n",
        "!python main.py \\\n",
        "--dataset oxford_pets \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "    --flag train_unet \\\n",
        "    --num_epoch 90 \\\n",
        "    --attack unet \\\n",
        "    --seed 1\\\n",
        "    --bs 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0dM4eQPZnEL",
        "outputId": "21ecb6f6-df4e-4b35-fc2a-73f18016faaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-05 05:05:15.325959: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 05:05:15.344157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762319115.366192   32423 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762319115.372875   32423 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762319115.390163   32423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319115.390197   32423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319115.390200   32423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319115.390202   32423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:05:15.395230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordFlowers\n",
            "Splitting data into 50% train, 20% val, and 30% test\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 419, in <module>\n",
            "    main(args)\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 349, in main\n",
            "    trainer = AdversarialTrainer(cfg, args)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 62, in __init__\n",
            "    self.trainer = build_trainer(cfg)\n",
            "                   ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/dass/engine/build.py\", line 11, in build_trainer\n",
            "    return TRAINER_REGISTRY.get(cfg.TRAINER.NAME)(cfg)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/dass/engine/trainer.py\", line 365, in __init__\n",
            "    self.build_data_loader()\n",
            "  File \"/content/MFCLIP_acv/dass/engine/trainer.py\", line 389, in build_data_loader\n",
            "    dm = DataManager(self.cfg, batch_size)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/dass/data/data_manager.py\", line 135, in __init__\n",
            "    dataset = build_dataset(cfg)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/dass/data/datasets/build.py\", line 11, in build_dataset\n",
            "    return DATASET_REGISTRY.get(cfg.DATASET.NAME)(cfg)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/datasets/oxford_flowers.py\", line 31, in __init__\n",
            "    train, val, test = self.read_data()\n",
            "                       ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/datasets/oxford_flowers.py\", line 75, in read_data\n",
            "    lab2cname = read_json(self.lab2cname_file)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/dass/utils/tools.py\", line 61, in read_json\n",
            "    with open(fpath, \"r\") as f:\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/data/oxford_flowers/cat_to_name.json'\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "command to train unet on different dataset\n",
        "\"\"\"\n",
        "!python main.py \\\n",
        "--dataset oxford_flowers \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_flowers.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "    --flag train_unet \\\n",
        "    --num_epoch 90 \\\n",
        "    --attack unet \\\n",
        "    --seed 1\\\n",
        "    --bs 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xMbjKuahfK7",
        "outputId": "0fb12d54-015d-464f-85b6-70428ea56505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-05 05:17:45.621021: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 05:17:45.639476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762319865.661851   36208 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762319865.668380   36208 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762319865.685612   36208 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319865.685648   36208 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319865.685652   36208 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319865.685655   36208 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:17:45.690516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "attack:ours, dataset:oxford_pets, target:rn18, ASR: 0.3987, clean: 0.5026, adv: 0.1038\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "run eval against target on oxford_pets\n",
        "\"\"\"\n",
        "\n",
        "#Note: I don't think that target flag really works, I think eval_adv tries to evaluate against all the targets listed on line 219 in main.py by default, so control it there\n",
        "!python main.py \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "        --flag eval_adv \\\n",
        "      --dataset oxford_pets \\\n",
        "       --target \"rn18\" \\\n",
        "      --seed 7 \\\n",
        "        --attack \"ours\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW-NmWu5akrz",
        "outputId": "e626a332-7691-4b85-fb7a-16bc4ecf9a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-05 05:50:42.492207: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 05:50:42.510739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762321842.532249   64706 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762321842.538836   64706 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762321842.556014   64706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762321842.556044   64706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762321842.556047   64706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762321842.556050   64706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:50:42.561041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading dataset: OxfordFlowers\n",
            "Reading split from /content/data/oxford_flowers/split_zhou_OxfordFlowers.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  -------------\n",
            "Dataset    OxfordFlowers\n",
            "# classes  102\n",
            "# train_x  4,093\n",
            "# val      1,633\n",
            "# test     2,463\n",
            "---------  -------------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a pink primrose, a type of flower.', 'a photo of a hard-leaved pocket orchid, a type of flower.', 'a photo of a canterbury bells, a type of flower.', 'a photo of a sweet pea, a type of flower.', 'a photo of a english marigold, a type of flower.', 'a photo of a tiger lily, a type of flower.', 'a photo of a moon orchid, a type of flower.', 'a photo of a bird of paradise, a type of flower.', 'a photo of a monkshood, a type of flower.', 'a photo of a globe thistle, a type of flower.', 'a photo of a snapdragon, a type of flower.', \"a photo of a colt's foot, a type of flower.\", 'a photo of a king protea, a type of flower.', 'a photo of a spear thistle, a type of flower.', 'a photo of a yellow iris, a type of flower.', 'a photo of a globe-flower, a type of flower.', 'a photo of a purple coneflower, a type of flower.', 'a photo of a peruvian lily, a type of flower.', 'a photo of a balloon flower, a type of flower.', 'a photo of a giant white arum lily, a type of flower.', 'a photo of a fire lily, a type of flower.', 'a photo of a pincushion flower, a type of flower.', 'a photo of a fritillary, a type of flower.', 'a photo of a red ginger, a type of flower.', 'a photo of a grape hyacinth, a type of flower.', 'a photo of a corn poppy, a type of flower.', 'a photo of a prince of wales feathers, a type of flower.', 'a photo of a stemless gentian, a type of flower.', 'a photo of a artichoke, a type of flower.', 'a photo of a sweet william, a type of flower.', 'a photo of a carnation, a type of flower.', 'a photo of a garden phlox, a type of flower.', 'a photo of a love in the mist, a type of flower.', 'a photo of a mexican aster, a type of flower.', 'a photo of a alpine sea holly, a type of flower.', 'a photo of a ruby-lipped cattleya, a type of flower.', 'a photo of a cape flower, a type of flower.', 'a photo of a great masterwort, a type of flower.', 'a photo of a siam tulip, a type of flower.', 'a photo of a lenten rose, a type of flower.', 'a photo of a barbeton daisy, a type of flower.', 'a photo of a daffodil, a type of flower.', 'a photo of a sword lily, a type of flower.', 'a photo of a poinsettia, a type of flower.', 'a photo of a bolero deep blue, a type of flower.', 'a photo of a wallflower, a type of flower.', 'a photo of a marigold, a type of flower.', 'a photo of a buttercup, a type of flower.', 'a photo of a oxeye daisy, a type of flower.', 'a photo of a common dandelion, a type of flower.', 'a photo of a petunia, a type of flower.', 'a photo of a wild pansy, a type of flower.', 'a photo of a primula, a type of flower.', 'a photo of a sunflower, a type of flower.', 'a photo of a pelargonium, a type of flower.', 'a photo of a bishop of llandaff, a type of flower.', 'a photo of a gaura, a type of flower.', 'a photo of a geranium, a type of flower.', 'a photo of a orange dahlia, a type of flower.', 'a photo of a pink-yellow dahlia, a type of flower.', 'a photo of a cautleya spicata, a type of flower.', 'a photo of a japanese anemone, a type of flower.', 'a photo of a black-eyed susan, a type of flower.', 'a photo of a silverbush, a type of flower.', 'a photo of a californian poppy, a type of flower.', 'a photo of a osteospermum, a type of flower.', 'a photo of a spring crocus, a type of flower.', 'a photo of a bearded iris, a type of flower.', 'a photo of a windflower, a type of flower.', 'a photo of a tree poppy, a type of flower.', 'a photo of a gazania, a type of flower.', 'a photo of a azalea, a type of flower.', 'a photo of a water lily, a type of flower.', 'a photo of a rose, a type of flower.', 'a photo of a thorn apple, a type of flower.', 'a photo of a morning glory, a type of flower.', 'a photo of a passion flower, a type of flower.', 'a photo of a lotus, a type of flower.', 'a photo of a toad lily, a type of flower.', 'a photo of a anthurium, a type of flower.', 'a photo of a frangipani, a type of flower.', 'a photo of a clematis, a type of flower.', 'a photo of a hibiscus, a type of flower.', 'a photo of a columbine, a type of flower.', 'a photo of a desert-rose, a type of flower.', 'a photo of a tree mallow, a type of flower.', 'a photo of a magnolia, a type of flower.', 'a photo of a cyclamen, a type of flower.', 'a photo of a watercress, a type of flower.', 'a photo of a canna lily, a type of flower.', 'a photo of a hippeastrum, a type of flower.', 'a photo of a bee balm, a type of flower.', 'a photo of a ball moss, a type of flower.', 'a photo of a foxglove, a type of flower.', 'a photo of a bougainvillea, a type of flower.', 'a photo of a camellia, a type of flower.', 'a photo of a mallow, a type of flower.', 'a photo of a mexican petunia, a type of flower.', 'a photo of a bromelia, a type of flower.', 'a photo of a blanket flower, a type of flower.', 'a photo of a trumpet creeper, a type of flower.', 'a photo of a blackberry lily, a type of flower.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "attack:ours, dataset:oxford_flowers, target:rn18, ASR: 0.2944, clean: 0.8384, adv: 0.5441\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "run eval against target on oxford flowers\n",
        "\"\"\"\n",
        "!python main.py \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_flowers.yaml \\\n",
        "        --flag eval_adv \\\n",
        "      --dataset oxford_flowers \\\n",
        "       --target \"rn18\" \\\n",
        "      --seed 7 \\\n",
        "        --attack \"ours\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxRJnRXWH0_O",
        "outputId": "3458d771-a5b7-4af2-f110-00c9ce60bf88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
