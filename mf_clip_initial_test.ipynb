{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1hamzaiqbal/MFCLIP_acv/blob/aidan%2Fgaussianlowpass/mf_clip_initial_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzfIg5NpoHNm",
        "outputId": "00b4d327-9834-4b1e-83b5-284704bd4460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  4 22:39:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0             54W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "/content\n",
            "Cloning into 'MFCLIP_acv'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 557 (delta 29), reused 10 (delta 10), pack-reused 519 (from 2)\u001b[K\n",
            "Receiving objects: 100% (557/557), 6.89 MiB | 29.14 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "/content/MFCLIP_acv\n"
          ]
        }
      ],
      "source": [
        "# 0) GPU + repo\n",
        "!nvidia-smi\n",
        "%cd /content\n",
        "!git clone https://github.com/1hamzaiqbal/MFCLIP_acv.git\n",
        "%cd MFCLIP_acv/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Deps\n",
        "!pip install torch torchvision timm einops yacs tqdm opencv-python scikit-learn scipy pyyaml ruamel.yaml ignite pytorch-ignite foolbox pandas matplotlib seaborn wilds ftfy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDljgHXio74B",
        "outputId": "46816da3-62a1-4cd6-a98c-506afa0a0fe8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.21)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ignite\n",
            "  Downloading ignite-1.1.0-py2.py3-none-any.whl.metadata (856 bytes)\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ignite) (2.32.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from ignite) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pytorch-ignite) (25.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from foolbox) (3.1.45)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds) (2.5.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ignite) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading pytorch_ignite-0.5.3-py3-none-any.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.8/343.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: yacs, ruamel.yaml.clib, littleutils, ftfy, eagerpy, ruamel.yaml, outdated, ignite, foolbox, pytorch-ignite, ogb, wilds\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4 ftfy-6.3.1 ignite-1.1.0 littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 pytorch-ignite-0.5.3 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 wilds-2.0.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Data (example: Oxford Pets into /content/data/oxford_pets)\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "root = Path(\"/content/data/\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "_ = OxfordIIITPet(root=str(root), download=True, transform=transforms.ToTensor())\n",
        "print(\"Oxford Pets downloaded to\", root)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfYAXPuMo_WM",
        "outputId": "0ed8de59-c1d7-4e0d-e99f-f636e282042f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:03<00:00, 243MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:00<00:00, 122MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oxford Pets downloaded to /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Finetune CLIP on a tiny subset (fast Colab run)\n",
        "#   flags/args come from main.py (see --flag, --dataset, --num_epoch, --bs, --lr, etc.)\n",
        "!python main.py \\\n",
        "  --flag finetune \\\n",
        "  --dataset oxford_pets \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "  --surrogate RN50 \\\n",
        "  --head ArcFace \\\n",
        "  --num_epoch 5 \\\n",
        "  --bs 64 \\\n",
        "  --lr 0.01 \\\n",
        "  --optimizer SGD \\\n",
        "  --ratio 0.2 \\\n",
        "  --device cuda:0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z8EzZ8HpFC6",
        "outputId": "2ff54808-7680-4f6a-bf9a-01c93975c44d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 22:40:51.596626: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-04 22:40:51.613440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762296051.635169    2339 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762296051.641690    2339 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762296051.658074    2339 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296051.658103    2339 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296051.658106    2339 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296051.658109    2339 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 22:40:51.663084: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Splitting trainval into 80% train and 20% val\n",
            "Saved split to /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "100%|████████████████████████████████████████| 244M/244M [00:01<00:00, 136MiB/s]\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "head param:\n",
            "{'feat_dim': 1024, 'num_class': 37, 'margin_arc': 0.15, 'margin_am': 0.0, 'scale': 16}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 408, in <module>\n",
            "    main(args)\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 339, in main\n",
            "    trainer.run()\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 320, in run\n",
            "    self.finetune(num_epoch=args.num_epoch)\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 128, in finetune\n",
            "    train_acc, loss = self.train_one_epoch(self.surrogate, train_acc, loader)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 162, in train_one_epoch\n",
            "    train_acc.update((outputs, labels))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ignite/metrics/metric.py\", line 872, in wrapper\n",
            "    func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ignite/metrics/accuracy.py\", line 258, in update\n",
            "    self._num_correct += torch.sum(correct).to(self._device)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset oxford_pets --root /content/data --dataset-config-file configs/datasets/oxford_pets.yaml --config-file configs/trainers/CoOp/rn50.yaml --flag train_scratch \\\n",
        "        --num_epoch 300 \\\n",
        "        --target \"rn18\" \\\n",
        "        --lr 0.1 \\\n",
        "        --bs 128"
      ],
      "metadata": {
        "id": "8L4JipAfqEIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e28d99-9e33-4357-96ce-f9f2cbb4ba49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 22:43:29.015362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-04 22:43:29.032814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762296209.054026    3227 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762296209.060501    3227 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762296209.076807    3227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296209.076835    3227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296209.076838    3227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762296209.076841    3227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 22:43:29.081681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "Epoch: 0, train acc: 0.0363, loss: 4.222040\n",
            "Epoch: 1, train acc: 0.0445, loss: 3.819193\n",
            "Epoch: 2, train acc: 0.0493, loss: 3.557514\n",
            "Epoch: 3, train acc: 0.0649, loss: 3.480029\n",
            "Epoch: 4, train acc: 0.0744, loss: 3.450997\n",
            "Epoch: 5, train acc: 0.0941, loss: 3.410273\n",
            "Epoch: 6, train acc: 0.0883, loss: 3.381672\n",
            "Epoch: 7, train acc: 0.0941, loss: 3.353474\n",
            "Epoch: 8, train acc: 0.1046, loss: 3.304960\n",
            "Epoch: 9, train acc: 0.1053, loss: 3.277341\n",
            "Epoch: 10, train acc: 0.1189, loss: 3.212152\n",
            "Epoch: 11, train acc: 0.1311, loss: 3.187642\n",
            "Epoch: 12, train acc: 0.1362, loss: 3.152345\n",
            "Epoch: 13, train acc: 0.1457, loss: 3.096401\n",
            "Epoch: 14, train acc: 0.1562, loss: 3.095021\n",
            "Epoch: 15, train acc: 0.1668, loss: 3.038111\n",
            "Epoch: 16, train acc: 0.1644, loss: 3.060315\n",
            "Epoch: 17, train acc: 0.1834, loss: 3.007816\n",
            "Epoch: 18, train acc: 0.1990, loss: 2.925598\n",
            "Epoch: 19, train acc: 0.1967, loss: 2.950514\n",
            "Epoch: 20, train acc: 0.1977, loss: 2.908172\n",
            "Epoch: 21, train acc: 0.2252, loss: 2.795244\n",
            "Epoch: 22, train acc: 0.2062, loss: 2.823567\n",
            "Epoch: 23, train acc: 0.2337, loss: 2.774047\n",
            "Epoch: 24, train acc: 0.2368, loss: 2.692344\n",
            "Epoch: 25, train acc: 0.2677, loss: 2.664352\n",
            "Epoch: 26, train acc: 0.2677, loss: 2.594616\n",
            "Epoch: 27, train acc: 0.2846, loss: 2.564781\n",
            "Epoch: 28, train acc: 0.2826, loss: 2.577834\n",
            "Epoch: 29, train acc: 0.2959, loss: 2.509571\n",
            "Epoch: 30, train acc: 0.3088, loss: 2.457399\n",
            "Epoch: 31, train acc: 0.3101, loss: 2.437517\n",
            "Epoch: 32, train acc: 0.3397, loss: 2.346472\n",
            "Epoch: 33, train acc: 0.3346, loss: 2.358993\n",
            "Epoch: 34, train acc: 0.3478, loss: 2.313830\n",
            "Epoch: 35, train acc: 0.3519, loss: 2.280546\n",
            "Epoch: 36, train acc: 0.3448, loss: 2.291079\n",
            "Epoch: 37, train acc: 0.3781, loss: 2.177249\n",
            "Epoch: 38, train acc: 0.3964, loss: 2.102052\n",
            "Epoch: 39, train acc: 0.4168, loss: 2.045657\n",
            "Epoch: 40, train acc: 0.4368, loss: 1.957346\n",
            "Epoch: 41, train acc: 0.4310, loss: 1.954116\n",
            "Epoch: 42, train acc: 0.4161, loss: 1.985558\n",
            "Epoch: 43, train acc: 0.4457, loss: 1.900831\n",
            "Epoch: 44, train acc: 0.4694, loss: 1.817043\n",
            "Epoch: 45, train acc: 0.4718, loss: 1.831143\n",
            "Epoch: 46, train acc: 0.4847, loss: 1.785654\n",
            "Epoch: 47, train acc: 0.4959, loss: 1.721455\n",
            "Epoch: 48, train acc: 0.5204, loss: 1.666913\n",
            "Epoch: 49, train acc: 0.5214, loss: 1.662690\n",
            "Epoch: 50, train acc: 0.5367, loss: 1.574854\n",
            "Epoch: 51, train acc: 0.5574, loss: 1.539128\n",
            "Epoch: 52, train acc: 0.5567, loss: 1.530324\n",
            "Epoch: 53, train acc: 0.5727, loss: 1.489637\n",
            "Epoch: 54, train acc: 0.5795, loss: 1.437665\n",
            "Epoch: 55, train acc: 0.5988, loss: 1.406518\n",
            "Epoch: 56, train acc: 0.6063, loss: 1.371365\n",
            "Epoch: 57, train acc: 0.5978, loss: 1.305199\n",
            "Epoch: 58, train acc: 0.6284, loss: 1.262363\n",
            "Epoch: 59, train acc: 0.6342, loss: 1.243612\n",
            "Epoch: 60, train acc: 0.6549, loss: 1.180499\n",
            "Epoch: 61, train acc: 0.6325, loss: 1.225824\n",
            "Epoch: 62, train acc: 0.6583, loss: 1.176236\n",
            "Epoch: 63, train acc: 0.6600, loss: 1.166604\n",
            "Epoch: 64, train acc: 0.6705, loss: 1.122153\n",
            "Epoch: 65, train acc: 0.6851, loss: 1.074606\n",
            "Epoch: 66, train acc: 0.6957, loss: 1.036446\n",
            "Epoch: 67, train acc: 0.6929, loss: 1.062886\n",
            "Epoch: 68, train acc: 0.7014, loss: 1.000214\n",
            "Epoch: 69, train acc: 0.7371, loss: 0.941778\n",
            "Epoch: 70, train acc: 0.7405, loss: 0.907469\n",
            "Epoch: 71, train acc: 0.7368, loss: 0.918571\n",
            "Epoch: 72, train acc: 0.7476, loss: 0.895186\n",
            "Epoch: 73, train acc: 0.7412, loss: 0.875384\n",
            "Epoch: 74, train acc: 0.7578, loss: 0.823477\n",
            "Epoch: 75, train acc: 0.7585, loss: 0.829557\n",
            "Epoch: 76, train acc: 0.7734, loss: 0.774716\n",
            "Epoch: 77, train acc: 0.7687, loss: 0.791223\n",
            "Epoch: 78, train acc: 0.7741, loss: 0.777515\n",
            "Epoch: 79, train acc: 0.7918, loss: 0.722905\n",
            "Epoch: 80, train acc: 0.7877, loss: 0.711450\n",
            "Epoch: 81, train acc: 0.8207, loss: 0.649437\n",
            "Epoch: 82, train acc: 0.8105, loss: 0.657946\n",
            "Epoch: 83, train acc: 0.8424, loss: 0.582809\n",
            "Epoch: 84, train acc: 0.8135, loss: 0.667618\n",
            "Epoch: 85, train acc: 0.8210, loss: 0.643211\n",
            "Epoch: 86, train acc: 0.8288, loss: 0.607719\n",
            "Epoch: 87, train acc: 0.8417, loss: 0.562123\n",
            "Epoch: 88, train acc: 0.8427, loss: 0.550141\n",
            "Epoch: 89, train acc: 0.8427, loss: 0.558238\n",
            "Epoch: 90, train acc: 0.8438, loss: 0.560872\n",
            "Epoch: 91, train acc: 0.8590, loss: 0.523120\n",
            "Epoch: 92, train acc: 0.8601, loss: 0.507421\n",
            "Epoch: 93, train acc: 0.8550, loss: 0.511807\n",
            "Epoch: 94, train acc: 0.8730, loss: 0.466357\n",
            "Epoch: 95, train acc: 0.8774, loss: 0.463691\n",
            "Epoch: 96, train acc: 0.8730, loss: 0.452053\n",
            "Epoch: 97, train acc: 0.8719, loss: 0.445627\n",
            "Epoch: 98, train acc: 0.8808, loss: 0.441248\n",
            "Epoch: 99, train acc: 0.8818, loss: 0.424468\n",
            "Epoch: 100, train acc: 0.8784, loss: 0.439221\n",
            "Epoch: 101, train acc: 0.8665, loss: 0.451082\n",
            "Epoch: 102, train acc: 0.8852, loss: 0.402864\n",
            "Epoch: 103, train acc: 0.8882, loss: 0.408311\n",
            "Epoch: 104, train acc: 0.8832, loss: 0.410284\n",
            "Epoch: 105, train acc: 0.8981, loss: 0.350049\n",
            "Epoch: 106, train acc: 0.8944, loss: 0.370509\n",
            "Epoch: 107, train acc: 0.9086, loss: 0.328966\n",
            "Epoch: 108, train acc: 0.9086, loss: 0.333095\n",
            "Epoch: 109, train acc: 0.9161, loss: 0.321763\n",
            "Epoch: 110, train acc: 0.9137, loss: 0.314674\n",
            "Epoch: 111, train acc: 0.9185, loss: 0.287328\n",
            "Epoch: 112, train acc: 0.9154, loss: 0.317532\n",
            "Epoch: 113, train acc: 0.9181, loss: 0.302716\n",
            "Epoch: 114, train acc: 0.9151, loss: 0.301115\n",
            "Epoch: 115, train acc: 0.9297, loss: 0.280906\n",
            "Epoch: 116, train acc: 0.9287, loss: 0.274028\n",
            "Epoch: 117, train acc: 0.9290, loss: 0.260913\n",
            "Epoch: 118, train acc: 0.9147, loss: 0.307875\n",
            "Epoch: 119, train acc: 0.9192, loss: 0.290129\n",
            "Epoch: 120, train acc: 0.9331, loss: 0.266435\n",
            "Epoch: 121, train acc: 0.9232, loss: 0.292699\n",
            "Epoch: 122, train acc: 0.9331, loss: 0.251992\n",
            "Epoch: 123, train acc: 0.9307, loss: 0.249689\n",
            "Epoch: 124, train acc: 0.9426, loss: 0.214920\n",
            "Epoch: 125, train acc: 0.9419, loss: 0.220147\n",
            "Epoch: 126, train acc: 0.9423, loss: 0.223332\n",
            "Epoch: 127, train acc: 0.9453, loss: 0.215802\n",
            "Epoch: 128, train acc: 0.9283, loss: 0.253789\n",
            "Epoch: 129, train acc: 0.9409, loss: 0.218111\n",
            "Epoch: 130, train acc: 0.9429, loss: 0.209651\n",
            "Epoch: 131, train acc: 0.9314, loss: 0.233314\n",
            "Epoch: 132, train acc: 0.9416, loss: 0.215965\n",
            "Epoch: 133, train acc: 0.9416, loss: 0.211022\n",
            "Epoch: 134, train acc: 0.9385, loss: 0.236291\n",
            "Epoch: 135, train acc: 0.9355, loss: 0.228862\n",
            "Epoch: 136, train acc: 0.9440, loss: 0.222228\n",
            "Epoch: 137, train acc: 0.9446, loss: 0.217291\n",
            "Epoch: 138, train acc: 0.9446, loss: 0.209564\n",
            "Epoch: 139, train acc: 0.9480, loss: 0.211508\n",
            "Epoch: 140, train acc: 0.9457, loss: 0.207724\n",
            "Epoch: 141, train acc: 0.9457, loss: 0.214831\n",
            "Epoch: 142, train acc: 0.9569, loss: 0.184759\n",
            "Epoch: 143, train acc: 0.9511, loss: 0.200259\n",
            "Epoch: 144, train acc: 0.9436, loss: 0.204922\n",
            "Epoch: 145, train acc: 0.9467, loss: 0.216478\n",
            "Epoch: 146, train acc: 0.9545, loss: 0.179185\n",
            "Epoch: 147, train acc: 0.9416, loss: 0.215913\n",
            "Epoch: 148, train acc: 0.9501, loss: 0.192260\n",
            "Epoch: 149, train acc: 0.9521, loss: 0.197874\n",
            "Epoch: 150, train acc: 0.7398, loss: 0.906825\n",
            "Epoch: 151, train acc: 0.4929, loss: 1.788645\n",
            "Epoch: 152, train acc: 0.5452, loss: 1.559197\n",
            "Epoch: 153, train acc: 0.5934, loss: 1.332546\n",
            "Epoch: 154, train acc: 0.6773, loss: 1.100527\n",
            "Epoch: 155, train acc: 0.6967, loss: 1.018800\n",
            "Epoch: 156, train acc: 0.6933, loss: 1.049019\n",
            "Epoch: 157, train acc: 0.7099, loss: 0.969117\n",
            "Epoch: 158, train acc: 0.7340, loss: 0.932028\n",
            "Epoch: 159, train acc: 0.7320, loss: 0.919689\n",
            "Epoch: 160, train acc: 0.7371, loss: 0.885773\n",
            "Epoch: 161, train acc: 0.7677, loss: 0.815699\n",
            "Epoch: 162, train acc: 0.7809, loss: 0.784407\n",
            "Epoch: 163, train acc: 0.7826, loss: 0.756002\n",
            "Epoch: 164, train acc: 0.7748, loss: 0.772815\n",
            "Epoch: 165, train acc: 0.7649, loss: 0.815569\n",
            "Epoch: 166, train acc: 0.7643, loss: 0.830052\n",
            "Epoch: 167, train acc: 0.7673, loss: 0.794527\n",
            "Epoch: 168, train acc: 0.7724, loss: 0.815043\n",
            "Epoch: 169, train acc: 0.7840, loss: 0.736238\n",
            "Epoch: 170, train acc: 0.7938, loss: 0.717064\n",
            "Epoch: 171, train acc: 0.8084, loss: 0.700273\n",
            "Epoch: 172, train acc: 0.7948, loss: 0.708016\n",
            "Epoch: 173, train acc: 0.7952, loss: 0.697796\n",
            "Epoch: 174, train acc: 0.7969, loss: 0.697844\n",
            "Epoch: 175, train acc: 0.7999, loss: 0.701325\n",
            "Epoch: 176, train acc: 0.7979, loss: 0.686349\n",
            "Epoch: 177, train acc: 0.8047, loss: 0.682858\n",
            "Epoch: 178, train acc: 0.8210, loss: 0.642482\n",
            "Epoch: 179, train acc: 0.8176, loss: 0.632027\n",
            "Epoch: 180, train acc: 0.8149, loss: 0.613961\n",
            "Epoch: 181, train acc: 0.8376, loss: 0.581127\n",
            "Epoch: 182, train acc: 0.8315, loss: 0.593358\n",
            "Epoch: 183, train acc: 0.8404, loss: 0.593386\n",
            "Epoch: 184, train acc: 0.8465, loss: 0.557193\n",
            "Epoch: 185, train acc: 0.8278, loss: 0.607119\n",
            "Epoch: 186, train acc: 0.8186, loss: 0.616983\n",
            "Epoch: 187, train acc: 0.8465, loss: 0.515358\n",
            "Epoch: 188, train acc: 0.8505, loss: 0.555865\n",
            "Epoch: 189, train acc: 0.8427, loss: 0.547064\n",
            "Epoch: 190, train acc: 0.8465, loss: 0.561719\n",
            "Epoch: 191, train acc: 0.8560, loss: 0.503552\n",
            "Epoch: 192, train acc: 0.8522, loss: 0.523668\n",
            "Epoch: 193, train acc: 0.8628, loss: 0.484332\n",
            "Epoch: 194, train acc: 0.8550, loss: 0.512487\n",
            "Epoch: 195, train acc: 0.8550, loss: 0.516777\n",
            "Epoch: 196, train acc: 0.8611, loss: 0.495488\n",
            "Epoch: 197, train acc: 0.8635, loss: 0.479905\n",
            "Epoch: 198, train acc: 0.8563, loss: 0.498425\n",
            "Epoch: 199, train acc: 0.8597, loss: 0.488253\n",
            "Epoch: 200, train acc: 0.8696, loss: 0.460452\n",
            "Epoch: 201, train acc: 0.8689, loss: 0.445882\n",
            "Epoch: 202, train acc: 0.8764, loss: 0.444356\n",
            "Epoch: 203, train acc: 0.8624, loss: 0.470521\n",
            "Epoch: 204, train acc: 0.8672, loss: 0.473425\n",
            "Epoch: 205, train acc: 0.8903, loss: 0.417807\n",
            "Epoch: 206, train acc: 0.8794, loss: 0.419405\n",
            "Epoch: 207, train acc: 0.8872, loss: 0.409618\n",
            "Epoch: 208, train acc: 0.8910, loss: 0.384205\n",
            "Epoch: 209, train acc: 0.8889, loss: 0.392929\n",
            "Epoch: 210, train acc: 0.8940, loss: 0.385411\n",
            "Epoch: 211, train acc: 0.8988, loss: 0.375719\n",
            "Epoch: 212, train acc: 0.8995, loss: 0.358096\n",
            "Epoch: 213, train acc: 0.8828, loss: 0.393750\n",
            "Epoch: 214, train acc: 0.8906, loss: 0.379436\n",
            "Epoch: 215, train acc: 0.9076, loss: 0.332644\n",
            "Epoch: 216, train acc: 0.9120, loss: 0.315075\n",
            "Epoch: 217, train acc: 0.8954, loss: 0.364220\n",
            "Epoch: 218, train acc: 0.8954, loss: 0.373853\n",
            "Epoch: 219, train acc: 0.9029, loss: 0.356761\n",
            "Epoch: 220, train acc: 0.9117, loss: 0.318803\n",
            "Epoch: 221, train acc: 0.9113, loss: 0.315692\n",
            "Epoch: 222, train acc: 0.9120, loss: 0.318334\n",
            "Epoch: 223, train acc: 0.9110, loss: 0.316746\n",
            "Epoch: 224, train acc: 0.9161, loss: 0.311327\n",
            "Epoch: 225, train acc: 0.9113, loss: 0.334575\n",
            "Epoch: 226, train acc: 0.9158, loss: 0.302071\n",
            "Epoch: 227, train acc: 0.9035, loss: 0.329213\n",
            "Epoch: 228, train acc: 0.9249, loss: 0.266628\n",
            "Epoch: 229, train acc: 0.9368, loss: 0.237178\n",
            "Epoch: 230, train acc: 0.9280, loss: 0.252329\n",
            "Epoch: 231, train acc: 0.9355, loss: 0.232822\n",
            "Epoch: 232, train acc: 0.9378, loss: 0.232765\n",
            "Epoch: 233, train acc: 0.9276, loss: 0.256088\n",
            "Epoch: 234, train acc: 0.9317, loss: 0.250925\n",
            "Epoch: 235, train acc: 0.9321, loss: 0.248354\n",
            "Epoch: 236, train acc: 0.9256, loss: 0.260456\n",
            "Epoch: 237, train acc: 0.9243, loss: 0.262783\n",
            "Epoch: 238, train acc: 0.9290, loss: 0.256301\n",
            "Epoch: 239, train acc: 0.9327, loss: 0.243953\n",
            "Epoch: 240, train acc: 0.9385, loss: 0.228511\n",
            "Epoch: 241, train acc: 0.9443, loss: 0.203810\n",
            "Epoch: 242, train acc: 0.9358, loss: 0.222532\n",
            "Epoch: 243, train acc: 0.9372, loss: 0.228381\n",
            "Epoch: 244, train acc: 0.9395, loss: 0.222650\n",
            "Epoch: 245, train acc: 0.9436, loss: 0.202168\n",
            "Epoch: 246, train acc: 0.9501, loss: 0.184224\n",
            "Epoch: 247, train acc: 0.9368, loss: 0.210334\n",
            "Epoch: 248, train acc: 0.9474, loss: 0.196276\n",
            "Epoch: 249, train acc: 0.9531, loss: 0.192716\n",
            "Epoch: 250, train acc: 0.9504, loss: 0.168733\n",
            "Epoch: 251, train acc: 0.9535, loss: 0.169366\n",
            "Epoch: 252, train acc: 0.9647, loss: 0.137378\n",
            "Epoch: 253, train acc: 0.9494, loss: 0.182998\n",
            "Epoch: 254, train acc: 0.9562, loss: 0.163560\n",
            "Epoch: 255, train acc: 0.9514, loss: 0.176273\n",
            "Epoch: 256, train acc: 0.9535, loss: 0.166515\n",
            "Epoch: 257, train acc: 0.9599, loss: 0.156718\n",
            "Epoch: 258, train acc: 0.9596, loss: 0.147989\n",
            "Epoch: 259, train acc: 0.9589, loss: 0.155174\n",
            "Epoch: 260, train acc: 0.9603, loss: 0.141176\n",
            "Epoch: 261, train acc: 0.9579, loss: 0.145925\n",
            "Epoch: 262, train acc: 0.9633, loss: 0.144150\n",
            "Epoch: 263, train acc: 0.9640, loss: 0.141823\n",
            "Epoch: 264, train acc: 0.9708, loss: 0.117230\n",
            "Epoch: 265, train acc: 0.9667, loss: 0.132800\n",
            "Epoch: 266, train acc: 0.9650, loss: 0.135137\n",
            "Epoch: 267, train acc: 0.9671, loss: 0.125493\n",
            "Epoch: 268, train acc: 0.9664, loss: 0.124128\n",
            "Epoch: 269, train acc: 0.9643, loss: 0.125784\n",
            "Epoch: 270, train acc: 0.9711, loss: 0.113009\n",
            "Epoch: 271, train acc: 0.9681, loss: 0.123725\n",
            "Epoch: 272, train acc: 0.9657, loss: 0.132230\n",
            "Epoch: 273, train acc: 0.9664, loss: 0.119151\n",
            "Epoch: 274, train acc: 0.9745, loss: 0.100007\n",
            "Epoch: 275, train acc: 0.9688, loss: 0.110242\n",
            "Epoch: 276, train acc: 0.9711, loss: 0.109767\n",
            "Epoch: 277, train acc: 0.9735, loss: 0.100703\n",
            "Epoch: 278, train acc: 0.9725, loss: 0.112951\n",
            "Epoch: 279, train acc: 0.9677, loss: 0.112296\n",
            "Epoch: 280, train acc: 0.9667, loss: 0.127090\n",
            "Epoch: 281, train acc: 0.9688, loss: 0.120350\n",
            "Epoch: 282, train acc: 0.9698, loss: 0.109403\n",
            "Epoch: 283, train acc: 0.9718, loss: 0.106938\n",
            "Epoch: 284, train acc: 0.9711, loss: 0.103496\n",
            "Epoch: 285, train acc: 0.9721, loss: 0.101119\n",
            "Epoch: 286, train acc: 0.9728, loss: 0.109622\n",
            "Epoch: 287, train acc: 0.9766, loss: 0.099280\n",
            "Epoch: 288, train acc: 0.9728, loss: 0.106631\n",
            "Epoch: 289, train acc: 0.9728, loss: 0.099603\n",
            "Epoch: 290, train acc: 0.9711, loss: 0.105282\n",
            "Epoch: 291, train acc: 0.9759, loss: 0.096591\n",
            "Epoch: 292, train acc: 0.9735, loss: 0.098048\n",
            "Epoch: 293, train acc: 0.9742, loss: 0.105110\n",
            "Epoch: 294, train acc: 0.9779, loss: 0.090866\n",
            "Epoch: 295, train acc: 0.9769, loss: 0.097271\n",
            "Epoch: 296, train acc: 0.9752, loss: 0.097033\n",
            "Epoch: 297, train acc: 0.9772, loss: 0.086902\n",
            "Epoch: 298, train acc: 0.9745, loss: 0.092390\n",
            "Epoch: 299, train acc: 0.9745, loss: 0.103281\n",
            "eval acc: 0.5026\n",
            "saved target model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "--dataset oxford_pets \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "    --flag train_unet \\\n",
        "    --num_epoch 90 \\\n",
        "    --attack unet \\\n",
        "    --seed 1\\\n",
        "    --bs 64"
      ],
      "metadata": {
        "id": "b_3qWsaMC7qL",
        "outputId": "46da2e1a-53bb-4b1d-c8cd-b5e39e032aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 23:59:18.532018: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-04 23:59:18.549558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762300758.571033   49122 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762300758.577443   49122 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762300758.593963   49122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762300758.593992   49122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762300758.593995   49122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762300758.593998   49122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 23:59:18.598861: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "head param:\n",
            "{'feat_dim': 1024, 'num_class': 37, 'margin_arc': 0.15, 'margin_am': 0.0, 'scale': 16}\n",
            "Epoch: 0, train acc: 0.1209, loss: 2.734717\n",
            "Epoch: 1, train acc: 0.0795, loss: 1.221176\n",
            "Epoch: 2, train acc: 0.0603, loss: -0.029953\n",
            "Epoch: 3, train acc: 0.0510, loss: -1.022739\n",
            "Epoch: 4, train acc: 0.0458, loss: -2.030686\n",
            "Epoch: 5, train acc: 0.0414, loss: -2.316007\n",
            "Epoch: 6, train acc: 0.0400, loss: -2.577334\n",
            "Epoch: 7, train acc: 0.0387, loss: -2.738990\n",
            "Epoch: 8, train acc: 0.0354, loss: -2.935548\n",
            "Epoch: 9, train acc: 0.0381, loss: -3.075489\n",
            "Epoch: 10, train acc: 0.0362, loss: -3.085261\n",
            "Epoch: 11, train acc: 0.0362, loss: -3.242415\n",
            "Epoch: 12, train acc: 0.0340, loss: -3.428967\n",
            "Epoch: 13, train acc: 0.0351, loss: -3.472740\n",
            "Epoch: 14, train acc: 0.0337, loss: -3.578838\n",
            "Epoch: 15, train acc: 0.0326, loss: -3.672887\n",
            "Epoch: 16, train acc: 0.0340, loss: -3.738578\n",
            "Epoch: 17, train acc: 0.0310, loss: -3.807063\n",
            "Epoch: 18, train acc: 0.0340, loss: -3.815502\n",
            "Epoch: 19, train acc: 0.0343, loss: -3.943419\n",
            "Epoch: 20, train acc: 0.0312, loss: -3.997302\n",
            "Epoch: 21, train acc: 0.0318, loss: -4.044635\n",
            "Epoch: 22, train acc: 0.0310, loss: -4.038932\n",
            "Epoch: 23, train acc: 0.0323, loss: -4.130629\n",
            "Epoch: 24, train acc: 0.0323, loss: -4.144710\n",
            "Epoch: 25, train acc: 0.0318, loss: -4.203251\n",
            "Epoch: 26, train acc: 0.0310, loss: -4.251156\n",
            "Epoch: 27, train acc: 0.0310, loss: -4.260851\n",
            "Epoch: 28, train acc: 0.0304, loss: -4.330995\n",
            "Epoch: 29, train acc: 0.0321, loss: -4.319771\n",
            "Epoch: 30, train acc: 0.0318, loss: -4.372877\n",
            "Epoch: 31, train acc: 0.0312, loss: -4.391685\n",
            "Epoch: 32, train acc: 0.0310, loss: -4.401665\n",
            "Epoch: 33, train acc: 0.0304, loss: -4.511790\n",
            "Epoch: 34, train acc: 0.0307, loss: -4.482162\n",
            "Epoch: 35, train acc: 0.0293, loss: -4.583696\n",
            "Epoch: 36, train acc: 0.0302, loss: -4.535833\n",
            "Epoch: 37, train acc: 0.0302, loss: -4.534662\n",
            "Epoch: 38, train acc: 0.0310, loss: -4.587720\n",
            "Epoch: 39, train acc: 0.0307, loss: -4.572932\n",
            "Epoch: 40, train acc: 0.0302, loss: -4.608673\n",
            "Epoch: 41, train acc: 0.0299, loss: -4.602057\n",
            "Epoch: 42, train acc: 0.0304, loss: -4.596789\n",
            "Epoch: 43, train acc: 0.0296, loss: -4.617655\n",
            "Epoch: 44, train acc: 0.0296, loss: -4.623508\n",
            "Epoch: 45, train acc: 0.0321, loss: -4.144316\n",
            "Epoch: 46, train acc: 0.0312, loss: -4.086257\n",
            "Epoch: 47, train acc: 0.0326, loss: -4.174015\n",
            "Epoch: 48, train acc: 0.0329, loss: -4.177891\n",
            "Epoch: 49, train acc: 0.0321, loss: -4.297692\n",
            "Epoch: 50, train acc: 0.0323, loss: -4.297759\n",
            "Epoch: 51, train acc: 0.0312, loss: -4.322540\n",
            "Epoch: 52, train acc: 0.0310, loss: -4.388275\n",
            "Epoch: 53, train acc: 0.0321, loss: -4.451024\n",
            "Epoch: 54, train acc: 0.0315, loss: -4.507599\n",
            "Epoch: 55, train acc: 0.0302, loss: -4.543476\n",
            "Epoch: 56, train acc: 0.0299, loss: -4.576091\n",
            "Epoch: 57, train acc: 0.0315, loss: -4.643517\n",
            "Epoch: 58, train acc: 0.0288, loss: -4.657176\n",
            "Epoch: 59, train acc: 0.0307, loss: -4.672937\n",
            "Epoch: 60, train acc: 0.0307, loss: -4.688529\n",
            "Epoch: 61, train acc: 0.0310, loss: -4.727586\n",
            "Epoch: 62, train acc: 0.0291, loss: -4.778141\n",
            "Epoch: 63, train acc: 0.0299, loss: -4.802198\n",
            "Epoch: 64, train acc: 0.0310, loss: -4.839073\n",
            "Epoch: 65, train acc: 0.0282, loss: -4.852503\n",
            "Epoch: 66, train acc: 0.0304, loss: -4.880874\n",
            "Epoch: 67, train acc: 0.0293, loss: -4.935953\n",
            "Epoch: 68, train acc: 0.0296, loss: -4.958814\n",
            "Epoch: 69, train acc: 0.0288, loss: -4.953257\n",
            "Epoch: 70, train acc: 0.0285, loss: -5.014208\n",
            "Epoch: 71, train acc: 0.0296, loss: -5.071440\n",
            "Epoch: 72, train acc: 0.0296, loss: -5.039753\n",
            "Epoch: 73, train acc: 0.0282, loss: -5.075938\n",
            "Epoch: 74, train acc: 0.0285, loss: -5.106764\n",
            "Epoch: 75, train acc: 0.0288, loss: -5.119924\n",
            "Epoch: 76, train acc: 0.0293, loss: -5.117317\n",
            "Epoch: 77, train acc: 0.0296, loss: -5.157709\n",
            "Epoch: 78, train acc: 0.0288, loss: -5.147358\n",
            "Epoch: 79, train acc: 0.0296, loss: -5.196499\n",
            "Epoch: 80, train acc: 0.0288, loss: -5.181712\n",
            "Epoch: 81, train acc: 0.0282, loss: -5.183295\n",
            "Epoch: 82, train acc: 0.0288, loss: -5.201869\n",
            "Epoch: 83, train acc: 0.0285, loss: -5.244456\n",
            "Epoch: 84, train acc: 0.0285, loss: -5.299872\n",
            "Epoch: 85, train acc: 0.0291, loss: -5.254779\n",
            "Epoch: 86, train acc: 0.0293, loss: -5.243420\n",
            "Epoch: 87, train acc: 0.0293, loss: -5.250502\n",
            "Epoch: 88, train acc: 0.0293, loss: -5.296339\n",
            "Epoch: 89, train acc: 0.0282, loss: -5.310914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "        --flag eval_adv \\\n",
        "      --dataset oxford_pets \\\n",
        "       --target \"rn18\" \\\n",
        "      --seed 1 \\\n",
        "        --attack \"ours\""
      ],
      "metadata": {
        "id": "3xMbjKuahfK7",
        "outputId": "8e7c674d-50aa-4c1b-a333-8273a51767c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-05 01:01:13.724637: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-05 01:01:13.742186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762304473.763557   70789 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762304473.770010   70789 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762304473.786562   70789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762304473.786605   70789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762304473.786609   70789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762304473.786613   70789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 01:01:13.791737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "torch.Size([1, 3, 224, 224])\n",
            "Loading trainer: ZeroshotCLIP\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading dataset: OxfordPets\n",
            "Reading split from /content/data/oxford_pets/split_zhou_OxfordPets.json\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0, 0, 0], std=[1, 1, 1])\n",
            "---------  ----------\n",
            "Dataset    OxfordPets\n",
            "# classes  37\n",
            "# train_x  2,944\n",
            "# val      736\n",
            "# test     3,669\n",
            "---------  ----------\n",
            "Loading CLIP (backbone: RN50)\n",
            "Prompts: ['a photo of a abyssinian, a type of pet.', 'a photo of a american bulldog, a type of pet.', 'a photo of a american pit bull terrier, a type of pet.', 'a photo of a basset hound, a type of pet.', 'a photo of a beagle, a type of pet.', 'a photo of a bengal, a type of pet.', 'a photo of a birman, a type of pet.', 'a photo of a bombay, a type of pet.', 'a photo of a boxer, a type of pet.', 'a photo of a british shorthair, a type of pet.', 'a photo of a chihuahua, a type of pet.', 'a photo of a egyptian mau, a type of pet.', 'a photo of a english cocker spaniel, a type of pet.', 'a photo of a english setter, a type of pet.', 'a photo of a german shorthaired, a type of pet.', 'a photo of a great pyrenees, a type of pet.', 'a photo of a havanese, a type of pet.', 'a photo of a japanese chin, a type of pet.', 'a photo of a keeshond, a type of pet.', 'a photo of a leonberger, a type of pet.', 'a photo of a maine coon, a type of pet.', 'a photo of a miniature pinscher, a type of pet.', 'a photo of a newfoundland, a type of pet.', 'a photo of a persian, a type of pet.', 'a photo of a pomeranian, a type of pet.', 'a photo of a pug, a type of pet.', 'a photo of a ragdoll, a type of pet.', 'a photo of a russian blue, a type of pet.', 'a photo of a saint bernard, a type of pet.', 'a photo of a samoyed, a type of pet.', 'a photo of a scottish terrier, a type of pet.', 'a photo of a shiba inu, a type of pet.', 'a photo of a siamese, a type of pet.', 'a photo of a sphynx, a type of pet.', 'a photo of a staffordshire bull terrier, a type of pet.', 'a photo of a wheaten terrier, a type of pet.', 'a photo of a yorkshire terrier, a type of pet.']\n",
            "Loading evaluator: Classification\n",
            "dataset loaded\n",
            "attack:ours, dataset:oxford_pets, target:rn18, ASR: 0.4113, clean: 0.5026, adv: 0.0913\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 408, in <module>\n",
            "    main(args)\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 339, in main\n",
            "    trainer.run()\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 330, in run\n",
            "    self.eval_adv(batch_size=512)\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 213, in eval_adv\n",
            "    self.load_model(model=self.target,\n",
            "  File \"/content/MFCLIP_acv/main.py\", line 255, in load_model\n",
            "    model.load_state_dict(torch.load(ckpts, map_location='cpu'))\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/data/oxford_pets/eff.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JxRJnRXWH0_O",
        "outputId": "4f695916-9a8f-4d8e-fb17-af0b245d681e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}