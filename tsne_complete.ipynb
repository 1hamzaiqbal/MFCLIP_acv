{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete t-SNE Analysis: CLIP Features & Adversarial Attacks\n",
        "\n",
        "This notebook contains:\n",
        "\n",
        "**Part 1: CLIP Loss Function Comparison**\n",
        "- Vanilla CLIP vs ArcFace vs SigLip vs ArcFaceSigmoid\n",
        "- Both Euclidean AND Cosine metrics\n",
        "\n",
        "**Part 2: UNet Adversarial Feature Analysis**\n",
        "- Clean vs UNet Vanilla vs UNet Contrastive\n",
        "- Feature disruption metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: GPU + Repo Setup\n",
        "!nvidia-smi\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"MFCLIP_acv\"):\n",
        "    !git clone -b hamza/discrim https://github.com/1hamzaiqbal/MFCLIP_acv\n",
        "\n",
        "%cd MFCLIP_acv\n",
        "!git fetch --all\n",
        "!git reset --hard origin/hamza/discrim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Install Dependencies\n",
        "!pip install -q torch torchvision timm einops yacs tqdm opencv-python scikit-learn scipy pyyaml ruamel.yaml pytorch-ignite foolbox pandas matplotlib seaborn wilds ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Mount Drive + Setup Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Dataset setup\n",
        "root = Path(\"/content/data/oxford_pets\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "_ = OxfordIIITPet(root=str(root), download=True, transform=transforms.ToTensor())\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"/content/data/oxford_pets/images\"):\n",
        "    print(\"Downloading images and annotations...\")\n",
        "    !wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "    !wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "    !tar -xf images.tar.gz -C /content/data/oxford_pets\n",
        "    !tar -xf annotations.tar.gz -C /content/data/oxford_pets\n",
        "    !rm -f images.tar.gz annotations.tar.gz\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/grad/comp_vision/hanson_loss/oxford_pets\"\n",
        "print(f\"\\nDrive root: {DRIVE_ROOT}\")\n",
        "print(\"\\nAvailable checkpoints:\")\n",
        "if os.path.exists(DRIVE_ROOT):\n",
        "    for f in sorted(os.listdir(DRIVE_ROOT)):\n",
        "        if f.endswith('.pth') or f.endswith('.pt'):\n",
        "            print(f\"  {f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Setup Python Path + Extract CLIP Features\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/MFCLIP_acv/lpclip\")\n",
        "sys.path.insert(0, \"/content/MFCLIP_acv\")\n",
        "os.makedirs(\"/content/MFCLIP_acv/lpclip/datasets\", exist_ok=True)\n",
        "open(\"/content/MFCLIP_acv/lpclip/datasets/__init__.py\", \"a\").close()\n",
        "\n",
        "%cd /content/MFCLIP_acv\n",
        "FEAT_DIR = \"/content/MFCLIP_acv/clip_feat\"\n",
        "\n",
        "print(\"Extracting vanilla CLIP features...\")\n",
        "!python -m lpclip.feat_extractor --split test --root /content/data --seed 1 \\\n",
        "    --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "    --config-file configs/trainers/CoOp/rn50_val.yaml \\\n",
        "    --output-dir {FEAT_DIR} --eval-only\n",
        "\n",
        "print(\"\\nFeature extraction complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# PART 1: CLIP Loss Function Comparison\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Load Features + Define Helper Functions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.spatial.distance import pdist, cosine\n",
        "from tqdm import tqdm\n",
        "\n",
        "FEAT_DIR = \"/content/MFCLIP_acv/clip_feat/OxfordPets\"\n",
        "OUT_DIR = \"/content/tsne_results\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load vanilla CLIP features\n",
        "d = np.load(f\"{FEAT_DIR}/test.npz\")\n",
        "X_vanilla = d[\"feature_list\"].astype(np.float32)\n",
        "y = d[\"label_list\"].astype(np.int64)\n",
        "print(f\"Loaded {len(X_vanilla)} samples, {len(np.unique(y))} classes, dim={X_vanilla.shape[1]}\")\n",
        "\n",
        "def torch_load_any(path):\n",
        "    sd = torch.load(path, map_location=\"cpu\")\n",
        "    return sd[\"state_dict\"] if isinstance(sd, dict) and \"state_dict\" in sd else sd\n",
        "\n",
        "def guess_head_weight(sd, in_dim):\n",
        "    cands = [(k,v) for k,v in sd.items() if isinstance(v, torch.Tensor) and v.ndim==2]\n",
        "    for k,v in cands:\n",
        "        if v.shape[0] == in_dim:\n",
        "            return v.numpy(), k\n",
        "    return None, None\n",
        "\n",
        "def cosine_project(X, W):\n",
        "    Xn = X / np.maximum(np.linalg.norm(X, axis=1, keepdims=True), 1e-12)\n",
        "    Wn = W / np.maximum(np.linalg.norm(W, axis=0, keepdims=True), 1e-12)\n",
        "    return Xn @ Wn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Define Checkpoint Paths (EDIT AS NEEDED)\n",
        "CHECKPOINTS = {\n",
        "    \"ArcFace\": f\"{DRIVE_ROOT}/RN50_ArcFace_oxford_pets.pth\",\n",
        "    \"ArcFaceSigmoid\": f\"{DRIVE_ROOT}/RN50_ArcFaceSigmoid_300ep.pth\",\n",
        "    \"SigLip\": f\"{DRIVE_ROOT}/RN50_SigLipHead_300ep.pth\",\n",
        "}\n",
        "\n",
        "# Build feature dict\n",
        "all_features = {\"Vanilla CLIP\": X_vanilla}\n",
        "\n",
        "for name, path in CHECKPOINTS.items():\n",
        "    if os.path.exists(path):\n",
        "        sd = torch_load_any(path)\n",
        "        W, key = guess_head_weight(sd, X_vanilla.shape[1])\n",
        "        if W is not None:\n",
        "            all_features[name] = cosine_project(X_vanilla, W)\n",
        "            print(f\"OK {name} - using {key}\")\n",
        "        else:\n",
        "            print(f\"SKIP {name} - no weights found\")\n",
        "    else:\n",
        "        print(f\"MISSING {name}\")\n",
        "\n",
        "print(f\"\\nTotal variants: {len(all_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Run t-SNE with BOTH Euclidean and Cosine metrics\n",
        "results_euclidean = {}\n",
        "results_cosine = {}\n",
        "\n",
        "for name, X in all_features.items():\n",
        "    print(f\"\\nProcessing {name}...\")\n",
        "    \n",
        "    # Euclidean t-SNE\n",
        "    print(\"  Running Euclidean t-SNE...\")\n",
        "    Z_euc = TSNE(n_components=2, perplexity=30, random_state=42, init='pca', n_iter=1000).fit_transform(X)\n",
        "    sil_euc = silhouette_score(Z_euc, y)\n",
        "    results_euclidean[name] = {\"Z\": Z_euc, \"sil\": sil_euc}\n",
        "    \n",
        "    # Cosine t-SNE\n",
        "    print(\"  Running Cosine t-SNE...\")\n",
        "    X_norm = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    Z_cos = TSNE(n_components=2, perplexity=30, metric='cosine', random_state=42, init='random', n_iter=1000).fit_transform(X_norm)\n",
        "    sil_cos = silhouette_score(X_norm, y, metric='cosine')\n",
        "    results_cosine[name] = {\"Z\": Z_cos, \"sil\": sil_cos}\n",
        "    \n",
        "    print(f\"  Euclidean Sil: {sil_euc:.4f}, Cosine Sil: {sil_cos:.4f}\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Visualize BOTH metrics side by side\n",
        "n = len(all_features)\n",
        "fig, axes = plt.subplots(2, n, figsize=(5*n, 10), dpi=120)\n",
        "cmap = plt.cm.get_cmap('tab20', len(np.unique(y)))\n",
        "\n",
        "for idx, name in enumerate(all_features.keys()):\n",
        "    # Euclidean row\n",
        "    ax = axes[0, idx]\n",
        "    Z = results_euclidean[name][\"Z\"]\n",
        "    sil = results_euclidean[name][\"sil\"]\n",
        "    ax.scatter(Z[:, 0], Z[:, 1], c=y, s=8, alpha=0.7, cmap=cmap)\n",
        "    ax.set_title(f\"{name}\\nEuclidean Sil: {sil:.3f}\", fontsize=10)\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    if idx == 0:\n",
        "        ax.set_ylabel(\"EUCLIDEAN\", fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # Cosine row\n",
        "    ax = axes[1, idx]\n",
        "    Z = results_cosine[name][\"Z\"]\n",
        "    sil = results_cosine[name][\"sil\"]\n",
        "    ax.scatter(Z[:, 0], Z[:, 1], c=y, s=8, alpha=0.7, cmap=cmap)\n",
        "    ax.set_title(f\"{name}\\nCosine Sil: {sil:.3f}\", fontsize=10)\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    if idx == 0:\n",
        "        ax.set_ylabel(\"COSINE\", fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.suptitle(\"CLIP Features: Euclidean vs Cosine Metrics\", fontsize=14, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_DIR}/clip_euclidean_vs_cosine.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Summary Table for CLIP Loss Comparison\n",
        "print(\"=\" * 70)\n",
        "print(\"CLIP LOSS FUNCTION COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Loss':<20} {'Euclidean Sil':>15} {'Cosine Sil':>15} {'Winner':>12}\")\n",
        "print(\"-\" * 70)\n",
        "for name in all_features.keys():\n",
        "    euc = results_euclidean[name][\"sil\"]\n",
        "    cos = results_cosine[name][\"sil\"]\n",
        "    winner = \"Cosine\" if cos > euc else \"Euclidean\"\n",
        "    print(f\"{name:<20} {euc:>15.4f} {cos:>15.4f} {winner:>12}\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nNote: ArcFace/SigLip optimize for angular separation,\")\n",
        "print(\"so Cosine silhouette is the 'correct' metric for them.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# PART 2: UNet Adversarial Feature Analysis\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Load Surrogate Model for Feature Extraction\n",
        "%cd /content/MFCLIP_acv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from ruamel.yaml import YAML\n",
        "\n",
        "from model import UNetLikeGenerator as UNet\n",
        "from utils.util import setup_cfg, Model\n",
        "from dass.engine import build_trainer\n",
        "from loss.head.head_def import HeadFactory\n",
        "\n",
        "import trainers.zsclip, trainers.coop, trainers.cocoop\n",
        "import datasets.oxford_pets, datasets.oxford_flowers, datasets.food101\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Args:\n",
        "    root = \"/content/data\"\n",
        "    dataset = \"oxford_pets\"\n",
        "    config_file = \"configs/trainers/CoOp/rn50.yaml\"\n",
        "    dataset_config_file = \"configs/datasets/oxford_pets.yaml\"\n",
        "    trainer = \"ZeroshotCLIP\"\n",
        "    head = \"ArcFace\"\n",
        "    output_dir = \"output\"\n",
        "    opts = []\n",
        "    gpu = 0\n",
        "    device = \"cuda:0\"\n",
        "    resume = \"\"\n",
        "    seed = -1\n",
        "    source_domains = None\n",
        "    target_domains = None\n",
        "    transforms = None\n",
        "    backbone = \"\"\n",
        "    bs = 64\n",
        "    ratio = 1.0\n",
        "\n",
        "args = Args()\n",
        "cfg = setup_cfg(args)\n",
        "trainer = build_trainer(cfg)\n",
        "\n",
        "yaml_parser = YAML(typ='safe')\n",
        "config = yaml_parser.load(open('configs/data.yaml', 'r'))\n",
        "config['num_classes'] = trainer.dm.num_classes\n",
        "config['output_dim'] = 1024\n",
        "head_factory = HeadFactory(args.head, config)\n",
        "\n",
        "clip_backbone = trainer.clip_model.visual\n",
        "normalize = transforms.Normalize([0.48145466, 0.4578275, 0.40821073], [0.26862954, 0.26130258, 0.27577711])\n",
        "backbone = nn.Sequential(normalize, clip_backbone)\n",
        "\n",
        "surrogate = Model(backbone, head_factory).to(device)\n",
        "\n",
        "# Load surrogate weights\n",
        "SURROGATE_PATH = f\"{DRIVE_ROOT}/RN50_ArcFace_oxford_pets.pth\"\n",
        "if os.path.exists(SURROGATE_PATH):\n",
        "    surrogate.load_state_dict(torch.load(SURROGATE_PATH, map_location=device))\n",
        "    print(f\"Surrogate loaded from {SURROGATE_PATH}\")\n",
        "surrogate.eval()\n",
        "\n",
        "test_loader = trainer.test_loader\n",
        "NUM_CLASSES = trainer.dm.num_classes\n",
        "print(f\"Test set: {len(test_loader.dataset)} samples, {NUM_CLASSES} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Load UNet Generators\n",
        "UNET_VANILLA_PATH = f\"{DRIVE_ROOT}/unet-vanilla-pets.pt\"\n",
        "UNET_CONTRASTIVE_PATH = f\"{DRIVE_ROOT}/unet-contrastive-pets.pt\"\n",
        "\n",
        "unet_vanilla = None\n",
        "unet_contrastive = None\n",
        "\n",
        "if os.path.exists(UNET_VANILLA_PATH):\n",
        "    unet_vanilla = UNet().to(device)\n",
        "    unet_vanilla.load_state_dict(torch.load(UNET_VANILLA_PATH, map_location=device))\n",
        "    unet_vanilla.eval()\n",
        "    print(f\"OK UNet Vanilla\")\n",
        "else:\n",
        "    print(f\"MISSING UNet Vanilla at {UNET_VANILLA_PATH}\")\n",
        "\n",
        "if os.path.exists(UNET_CONTRASTIVE_PATH):\n",
        "    unet_contrastive = UNet().to(device)\n",
        "    unet_contrastive.load_state_dict(torch.load(UNET_CONTRASTIVE_PATH, map_location=device))\n",
        "    unet_contrastive.eval()\n",
        "    print(f\"OK UNet Contrastive\")\n",
        "else:\n",
        "    print(f\"MISSING UNet Contrastive at {UNET_CONTRASTIVE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Extract Clean and Adversarial Features\n",
        "NUM_SAMPLES = 1000\n",
        "EPS = 16/255.\n",
        "\n",
        "def extract_features(loader, backbone, generator=None, num_samples=1000, eps=16/255.):\n",
        "    backbone.eval()\n",
        "    if generator is not None:\n",
        "        generator.eval()\n",
        "    \n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    count = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Extracting\"):\n",
        "            images = batch['img'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            if generator is not None:\n",
        "                try:\n",
        "                    target_labels = torch.randint(0, NUM_CLASSES, labels.shape).to(device)\n",
        "                    noise = generator(images, target_labels)\n",
        "                except TypeError:\n",
        "                    noise = generator(images)\n",
        "                noise = torch.clamp(noise, -eps, eps)\n",
        "                images = torch.clamp(images + noise, 0, 1)\n",
        "            \n",
        "            features = backbone(images)\n",
        "            all_features.append(features.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            \n",
        "            count += len(labels)\n",
        "            if count >= num_samples:\n",
        "                break\n",
        "    \n",
        "    return np.concatenate(all_features)[:num_samples], np.concatenate(all_labels)[:num_samples]\n",
        "\n",
        "# Extract features\n",
        "print(\"Extracting clean features...\")\n",
        "feat_clean, labels_adv = extract_features(test_loader, surrogate.backbone, None, NUM_SAMPLES)\n",
        "\n",
        "adv_features = {\"Clean\": feat_clean}\n",
        "\n",
        "if unet_vanilla is not None:\n",
        "    print(\"Extracting UNet Vanilla adversarial features...\")\n",
        "    feat_unet_vanilla, _ = extract_features(test_loader, surrogate.backbone, unet_vanilla, NUM_SAMPLES, EPS)\n",
        "    adv_features[\"UNet Vanilla\"] = feat_unet_vanilla\n",
        "    del unet_vanilla\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "if unet_contrastive is not None:\n",
        "    print(\"Extracting UNet Contrastive adversarial features...\")\n",
        "    feat_unet_contrastive, _ = extract_features(test_loader, surrogate.backbone, unet_contrastive, NUM_SAMPLES, EPS)\n",
        "    adv_features[\"UNet Contrastive\"] = feat_unet_contrastive\n",
        "    del unet_contrastive\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"\\nExtracted: {list(adv_features.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13: t-SNE for Adversarial Features\n",
        "# Combine for joint t-SNE\n",
        "all_feats = []\n",
        "all_names = []\n",
        "indices = []\n",
        "start = 0\n",
        "\n",
        "for name, feats in adv_features.items():\n",
        "    all_feats.append(feats)\n",
        "    indices.append((name, start, start + len(feats)))\n",
        "    start += len(feats)\n",
        "\n",
        "combined = np.concatenate(all_feats)\n",
        "print(f\"Running joint t-SNE on {combined.shape[0]} samples...\")\n",
        "Z_all = TSNE(n_components=2, perplexity=30, random_state=42, init='pca', n_iter=1000).fit_transform(combined)\n",
        "\n",
        "# Visualize\n",
        "n = len(adv_features)\n",
        "fig, axes = plt.subplots(1, n+1, figsize=(5*(n+1), 5), dpi=120)\n",
        "cmap = plt.cm.get_cmap('tab20', len(np.unique(labels_adv)))\n",
        "\n",
        "for idx, (name, start, end) in enumerate(indices):\n",
        "    ax = axes[idx]\n",
        "    Z = Z_all[start:end]\n",
        "    ax.scatter(Z[:, 0], Z[:, 1], c=labels_adv, s=8, alpha=0.7, cmap=cmap)\n",
        "    ax.set_title(f\"{name}\\n(colored by class)\", fontsize=10)\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "# Overlay plot\n",
        "ax = axes[-1]\n",
        "colors = plt.cm.Set1(np.linspace(0, 1, len(indices)))\n",
        "markers = ['o', 's', '^', 'D', 'v']\n",
        "for idx, ((name, start, end), color, marker) in enumerate(zip(indices, colors, markers)):\n",
        "    Z = Z_all[start:end]\n",
        "    ax.scatter(Z[:, 0], Z[:, 1], c=[color], s=10, alpha=0.5, marker=marker, label=name)\n",
        "ax.legend(loc='upper right', fontsize=8)\n",
        "ax.set_title(\"All Overlaid\\n(colored by variant)\", fontsize=10)\n",
        "ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "plt.suptitle(\"t-SNE: Clean vs UNet Adversarial Features\", fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_DIR}/unet_adversarial_tsne.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 14: Feature Disruption Metrics\n",
        "print(\"=\" * 70)\n",
        "print(\"FEATURE DISRUPTION METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Generator':<20} {'Cosine Dist':>15} {'L2 Dist':>15}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "disruption_results = []\n",
        "for name, feats in adv_features.items():\n",
        "    if name == \"Clean\":\n",
        "        continue\n",
        "    \n",
        "    # Cosine distance per sample\n",
        "    cos_dists = [cosine(feat_clean[i], feats[i]) for i in range(len(feats))]\n",
        "    cos_mean, cos_std = np.mean(cos_dists), np.std(cos_dists)\n",
        "    \n",
        "    # L2 distance\n",
        "    l2_dists = np.linalg.norm(feat_clean - feats, axis=1)\n",
        "    l2_mean, l2_std = np.mean(l2_dists), np.std(l2_dists)\n",
        "    \n",
        "    print(f\"{name:<20} {cos_mean:>12.4f}+-{cos_std:.3f} {l2_mean:>12.2f}+-{l2_std:.2f}\")\n",
        "    disruption_results.append({\"Generator\": name, \"Cosine\": cos_mean, \"L2\": l2_mean})\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Higher = more disruption (better attack)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 15: Save All Results to Drive\n",
        "import shutil\n",
        "\n",
        "SAVE_DIR = f\"{DRIVE_ROOT}/tsne_complete_results\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "files = [\n",
        "    f\"{OUT_DIR}/clip_euclidean_vs_cosine.png\",\n",
        "    f\"{OUT_DIR}/unet_adversarial_tsne.png\",\n",
        "]\n",
        "\n",
        "print(f\"Saving to {SAVE_DIR}...\")\n",
        "for f in files:\n",
        "    if os.path.exists(f):\n",
        "        shutil.copy(f, SAVE_DIR)\n",
        "        print(f\"  OK {os.path.basename(f)}\")\n",
        "\n",
        "print(\"\\nDone! All results saved.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
