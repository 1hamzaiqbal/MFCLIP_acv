{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP/C1Y4OPM1AVC0IzZzAwsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1hamzaiqbal/MFCLIP_acv/blob/hamza%2Fdiscrim/mf_clip_finetune_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzfIg5NpoHNm",
        "outputId": "aaf5ad48-b1cd-40b0-e332-e75cb10e7107"
      },
      "outputs": [],
      "source": [
        "# 0) GPU + repo\n",
        "!nvidia-smi\n",
        "%cd /content\n",
        "!git clone -b hamza/discrim https://github.com/1hamzaiqbal/MFCLIP_acv\n",
        "%cd MFCLIP_acv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Deps\n",
        "!pip install torch torchvision timm einops yacs tqdm opencv-python scikit-learn scipy pyyaml ruamel.yaml pytorch-ignite foolbox pandas matplotlib seaborn wilds ftfy timm\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDljgHXio74B",
        "outputId": "2e148480-710d-42c8-d512-3ce5859b0a5e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Data (example: Oxford Pets into /content/data/oxford_pets)\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "root = Path(\"/content/data/oxford_pets\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "_ = OxfordIIITPet(root=str(root), download=True, transform=transforms.ToTensor())\n",
        "print(\"Oxford Pets downloaded to\", root)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfYAXPuMo_WM",
        "outputId": "ab05ec80-b19b-446f-906c-9409599d4926"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch official Oxford-IIIT Pet dataset (provides annotations/trainval.txt)\n",
        "%cd /content\n",
        "!mkdir -p /content/data/oxford_pets\n",
        "!wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz -C /content/data/oxford_pets\n",
        "!tar -xf annotations.tar.gz -C /content/data/oxford_pets\n",
        "!ls /content/data/oxford_pets/annotations | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gQQc7Lpug3S",
        "outputId": "0a0de4af-b4bd-47a3-94c3-de4a27009e8c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Finetune Surrogate (Required for generator training)\n",
        "# go to the repo root first\n",
        "%cd /content/MFCLIP_acv\n",
        "\n",
        "# (optional) quiet TF spam\n",
        "%env TF_CPP_MIN_LOG_LEVEL=2\n",
        "\n",
        "# run with repo-relative config paths (no MFCLIP_acv/ prefix)\n",
        "!python main.py \\\n",
        "  --flag finetune \\\n",
        "  --dataset oxford_pets \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "  --surrogate RN50 \\\n",
        "  --head ArcFace \\\n",
        "  --num_epoch 1 \\\n",
        "  --bs 64 \\\n",
        "  --lr 0.01 \\\n",
        "  --optimizer SGD \\\n",
        "  --ratio 0.2 \\\n",
        "  --device cuda:0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z8EzZ8HpFC6",
        "outputId": "ecf02a95-1367-4c86-f96e-660f282fad1e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Train ViT Generator\n",
        "!python main.py \\\n",
        "  --flag train_unet \\\n",
        "  --generator vit \\\n",
        "  --dataset oxford_pets \\\n",
        "  --root /content/data \\\n",
        "  --config-file configs/trainers/CoOp/rn50.yaml \\\n",
        "  --dataset-config-file configs/datasets/oxford_pets.yaml \\\n",
        "  --trainer ZeroshotCLIP \\\n",
        "  --surrogate RN50 \\\n",
        "  --head ArcFace \\\n",
        "  --num_epoch 1 \\\n",
        "  --bs 64 \\\n",
        "  --lr 0.01 \\\n",
        "  --optimizer SGD \\\n",
        "  --ratio 0.2 \\\n",
        "  --device cuda:0\n"
      ],
      "metadata": {
        "id": "8L4JipAfqEIB"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}